{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Datasets\n",
    "Specify the file paths to your CSV files and load them into DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (update these paths as necessary)\n",
    "manual_sensors_path = 'path/to/manual_sensors.csv'\n",
    "weather_data_path = 'data\\cleaned_data\\cleaned_weather_data.csv'\n",
    "\n",
    "# Load CSV files into DataFrames\n",
    "manual_sensors = pd.read_csv(manual_sensors_path)\n",
    "weather_data = pd.read_csv(weather_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "Ensure that the timestamp columns are in datetime format and set them as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, timestamp_column='timestamp'):\n",
    "    \"\"\"\n",
    "    Prepare DataFrame by converting timestamp column to datetime and setting it as the index.\n",
    "    Resample to hourly frequency and handle missing values.\n",
    "    \"\"\"\n",
    "    df[timestamp_column] = pd.to_datetime(df[timestamp_column])\n",
    "    df.set_index(timestamp_column, inplace=True)\n",
    "    df = df.asfreq('H')  # Set frequency to hourly\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')  # Impute missing values\n",
    "    return df\n",
    "\n",
    "# Prepare each dataset\n",
    "manual_sensors = prepare_data(manual_sensors, timestamp_column='timestamp')\n",
    "weather_data = prepare_data(weather_data, timestamp_column='timestamp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concatenate DataFrames\n",
    "Combine all datasets based on the timestamp index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of DataFrames to concatenate\n",
    "data_frames = [manual_sensors, weather_data]\n",
    "\n",
    "# Concatenate DataFrames on the timestamp index\n",
    "merged_data = reduce(lambda left, right: pd.concat([left, right], axis=1, join='inner'), data_frames)\n",
    "\n",
    "# Optional: Handle any remaining missing values\n",
    "merged_data.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "\n",
    "# Save the combined dataset to a new CSV\n",
    "merged_data.to_csv('path/to/merged_sensor_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Review the Combined Data\n",
    "Check the first few rows of the merged DataFrame to ensure it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the merged dataset\n",
    "merged_data.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bf_dssgx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
