# Assumptions about Data, Limitations, and Challenges

## Assumptions About Data Quality
We assumed that different data sources would have varying levels of data quality. Below is an outline of the assumptions made and findings discovered about the data quality of our primary data sources (i.e., visitor sensors, visitor center, weather, and parking data).

### Visitor Sensor Data
Sensor data is frequently operationalized as “ground truth” in social and methodological research because it does not suffer from the response errors typically associated with other data types, such as self-reports or observational data recorded by human coders. However, despite this common assumption among methodologists, we recognize that some unknown level of error may still be present in the visitor sensor data. We consider this data to be imperfect for the following reasons:

- Sensors do not identify unique visitors to the park, making them susceptible to double counting—an unknowable source of measurement error in the data.

- The limited number of sensors placed at non-random locations throughout the park introduces potential **bias**:
   - The absence of sensors at many other entry and exit points systematically underestimates the total number of visitors, making it difficult to accurately assess park occupancy.
    - The locations of the installed sensors do not adequately represent all areas of the park, which introduces bias in the visitor count estimates. For example, a popular trail that loops through the park has two entrances and one exit. A sensor is installed at Waldhausreibe, located at one of the entrances—the less frequented one. This resulted in a significant discrepancy between the number of visitors entering (IN) and exiting (OUT) the park, with the IN count for this sensor being notably lower than the OUT count. Below are graphs (Figure 1 and Figure 2) that illustrate this issue.
    - The absence of sensors at many other entry and exit points systematically underestimates the total number of visitors, making it difficult to accurately assess park occupancy.
    - The sensor data exhibit a "missing not at random" pattern (i.e., bias). Since the collection of visitor sensor data began in 2016, additional sensors have been installed over the years, leading to significant gaps in the dataset. Below is a graph (Figure 3) illustrating this issue: individual sensors are shown on the y-axis, while time (ranging from 2016 to 2024) is represented on the x-axis. In the graph, red indicates periods of missing data, while blue indicates when a sensor was installed, functioning, and actively collecting data.
        - Furthermore, sensors can malfunction and require repairs, while cloud-connected sensors may go offline, contributing to greater error **variance** in the estimates of park visitors.
- The mechanism that is used to count visitors using these sensors is generated by detection in changes of infrared radiation, typically emitted by warm objects, including humans and animals. Although pyro sensors are calibrated to detect the human body temperature, miscounting of other living organisms is possible.

<figure style={{ textAlign: "center" }}>
    <img src="assets\sensor-discrepancy-1.png" alt="Here the alt text"  style={{ display: "block", marginLeft: "auto", marginRight: "auto", marginBottom: "10px" }} width="700"/>
    <span style={{ color: "gray" }}><strong>Figure 1</strong>: Waldhausreibe Sensor Discrepancy in Overall Visitor Counts from 2016 to 2024 </span>
</figure>

<figure style={{ textAlign: "center" }}>
    <img src="assets\sensor-discrepancy-2.png" alt="Here the alt text"  style={{ display: "block", marginLeft: "auto", marginRight: "auto", marginBottom: "10px" }} width="700"/>
    <span style={{ color: "gray" }}><strong>Figure 2</strong>: Distrbution of Visitor Counts from Waldhausreibe Sensor by Hour of the Day</span>
</figure>

<figure style={{ textAlign: "center" }}>
    <img src="assets\Sensor missing data.png" alt="Here the alt text" style={{ display: "block", marginLeft: "auto", marginRight: "auto", marginBottom: "10px" }} width="700"/>
    <span style={{ color: "gray" }}><strong>Figure 3:</strong> Missing Visitor Sensor Data. The y-axis shows individual sensors, and the x-axis represents time (2016–2024). Red indicates missing data, with large blocks indicating pre-installation periods and smaller gaps reflecting intermittent outages. Blue indicates periods when sensors were installed and actively collecting data</span>
</figure>

### Visitor Center Data
Given that these data are counted manually and the data file itself uses manual data entry, we assumed that the data maintained in the visitor center data file has some unknowable source of human error (i.e., miscounting) as well as clerical errors in data entry. Many of the data used in the visitor center data is easily verifiable and thus fixable, such as the day of the week that a given date fell on, dates of national holidays, seasons, and whether or not visitor centers were open.

### Weather Data
Meteostat data is sourced from weather stations, and we assume the data is collected from reliable sources and is subject to quality control (though local microclimate variations may influence representativeness). Measurement techniques are expected to remain consistent over time, ensuring comparability across future years of deployment of our prediction model and dashboard. The temporal resolution (hourly) fit our analysis needs, and linear interpolation was used in rare cases of missing weather data.

### Parking Data
The sensor data used to identify occupied or vacant parking spaces appeared to be reliable insofar as only two of the twelve parking stations suffer from connectivity issues to the Bayern Cloud. Since the sampling of parking sensors is variable within and across sensors, analysis of historic parking could not be performed and these data were not usable in the prediction model. However we assume the the measurements taken by sensors are generally reliable.

## How Data Quality Limited the Design of Our Solution

### Operationalization of Target Variables

#### Park Occupancy - not possible
The quality of the visitor sensor data limited how the target variable of our prediction models could be operationalized. Ideally, the target of our prediction model would be the hourly occupancy of the Bavarian Forest National Park; this would allow park management to have an estimate of how many visitors will be in the park at any given hour within a one-week forecast horizon. However, the limited number of visitor sensors produces estimates that are far too low to accurately reflect park occupancy. This target variable was thus not used.

#### Traffic vs. IN and OUT
We then considered operationalizing the the target variable in our prediction models as "traffic". The idea was that summing the IN and OUT columns across sensors at the hourly level would give us a good sense of park activity. In other words, this operationalization would provide us with the amount of "traffic" passing by a visitor sensor, regardless of the direction the visitor is walking in.

We also explored using the sum of the IN columns across sensors and the sum of the OUT columns across sensors as two distinct targets. When we implemented this approach, the MSE of the models was reduced relative to the traffic target variable. Due to the improved model fit, we opted to use IN and OUT as separate target variables instead of traffic. It also makes sense to separate IN and OUT as two target variables from an a priori perspective; the time lag between people entering (IN) and exiting (OUT) makes it necessary to separate these as the predictions are at the hourly level. We also adopted this approach across the 15 regions defined by the Bavarian Forest National Park.

#### Ultimately Used Relative Trends in Visitor Estimation


#### Prediction level: Regions vs. Sensors vs. Trail Segments


### Time Frame for Training Data (Only 2023-2024) because of missing data

