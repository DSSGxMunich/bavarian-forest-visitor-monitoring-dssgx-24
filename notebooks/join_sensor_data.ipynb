{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw data\n",
    "file_path = \"\" # Define the path to the CSV file\n",
    "\n",
    "# Load the Excel file to a data frame\n",
    "df_mergedsensors = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_mergedsensors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns so Falkenstein 2 IN is before Falkenstein 2 Out\n",
    "df_mergedsensors = df_mergedsensors[['Time', 'Bayerisch Eisenstein IN', 'Bayerisch Eisenstein OUT', \n",
    "                                      'Brechhäuslau IN', 'Brechhäuslau OUT', 'Deffernik IN', 'Deffernik OUT', \n",
    "                                      'Diensthüttenstraße IN', 'Diensthüttenstraße OUT', 'Felswandergebiet IN', \n",
    "                                      'Felswandergebiet OUT', 'Ferdinandsthal IN', 'Ferdinandsthal OUT', 'Fredenbrücke IN', \n",
    "                                      'Fredenbrücke OUT', 'Gfäll IN', 'Gfäll OUT', 'Gsenget IN', 'Gsenget OUT', 'Klingenbrunner Wald IN', \n",
    "                                      'Klingenbrunner Wald OUT', 'Klosterfilz IN', 'Klosterfilz OUT', 'Racheldiensthütte IN', \n",
    "                                      'Racheldiensthütte OUT', 'Sagwassersäge IN', 'Sagwassersäge OUT', 'Scheuereck IN', \n",
    "                                      'Scheuereck OUT', 'Schillerstraße IN', 'Schillerstraße OUT', 'Schwarzbachbrücke IN', \n",
    "                                      'Schwarzbachbrücke OUT', 'Falkenstein 2 IN', 'Falkenstein 2 OUT', 'Lusen 2 IN', 'Lusen 2 OUT', \n",
    "                                      'Lusen 3 IN', 'Lusen 3 OUT', 'Waldhausreibe IN', 'Waldhausreibe OUT', 'Waldspielgelände IN', \n",
    "                                      'Waldspielgelände OUT', 'Wistlberg IN', 'Wistlberg OUT', 'Bucina MERGED IN', 'Bucina MERGED OUT', \n",
    "                                      'Falkenstein 1 MERGED IN', 'Falkenstein 1 MERGED OUT', 'Lusen 1 MERGED IN', 'Lusen 1 MERGED OUT', \n",
    "                                      'Trinkwassertalsperre MERGED IN', 'Trinkwassertalsperre MERGED OUT', 'traffic', \n",
    "                                      'sum_IN', 'sum_OUT', 'diff', 'occupancy', 'Unnamed: 0.1', 'Unnamed: 0', 'Temperature (°C)', \n",
    "                                      'Relative Humidity (%)', 'Precipitation (mm)', 'Wind Speed (km/h)', 'Sunshine Duration (min)', \n",
    "                                      'Tag', 'Monat', 'Jahr', 'Wochentag', 'Wochenende', 'Jahreszeit', 'Laubfärbung', \n",
    "                                      'Besuchszahlen_HEH', 'Besuchszahlen_HZW', 'Besuchszahlen_WGM', 'Parkpl_HEH_PKW', \n",
    "                                      'Parkpl_HEH_BUS', 'Parkpl_HZW_PKW', 'Parkpl_HZW_BUS', 'Schulferien_Bayern', \n",
    "                                      'Schulferien_CZ', 'Feiertag_Bayern', 'Feiertag_CZ', 'HEH_geoeffnet', 'HZW_geoeffnet', \n",
    "                                      'WGM_geoeffnet', 'Lusenschutzhaus_geoeffnet', 'Racheldiensthuette_geoeffnet', \n",
    "                                      'Waldschmidthaus_geoeffnet', 'Falkensteinschutzhaus_geoeffnet', 'Schwellhaeusl_geoeffnet', \n",
    "                                      'Temperatur', 'Niederschlagsmenge', 'Schneehoehe', 'GS mit', 'GS max', 'Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove MERGED from column names with this unnecessary label\n",
    "df_mergedsensors.columns = df_mergedsensors.columns.str.replace(' MERGED', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['traffic', 'sum_IN', 'sum_OUT', 'diff', 'occupancy', 'Unnamed: 0.1', 'Unnamed: 0', 'Total']\n",
    "df_mergedsensors = df_mergedsensors.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'Time' column is in datetime format\n",
    "df_mergedsensors['Time'] = pd.to_datetime(df_mergedsensors['Time'])\n",
    "\n",
    "# List of sensor columns to melt\n",
    "sensor_columns = [\n",
    "    'Bayerisch Eisenstein', 'Brechhäuslau', 'Bucina', 'Deffernik',\n",
    "    'Diensthüttenstraße', 'Falkenstein 1', 'Falkenstein 2',\n",
    "    'Felswandergebiet', 'Ferdinandsthal', 'Fredenbrücke', 'Gfäll',\n",
    "    'Gsenget', 'Klingenbrunner Wald', 'Klosterfilz', 'Lusen 1',\n",
    "    'Lusen 2', 'Lusen 3', 'Racheldiensthütte', 'Sagwassersäge',\n",
    "    'Scheuereck', 'Schillerstraße', 'Schwarzbachbrücke',\n",
    "    'Trinkwassertalsperre', 'Waldhausreibe', 'Waldspielgelände',\n",
    "    'Wistlberg'\n",
    "]\n",
    "\n",
    "# Create a list of columns for melting, including IN/OUT directions for each sensor\n",
    "melt_columns = [f'{sensor} IN' for sensor in sensor_columns] + [f'{sensor} OUT' for sensor in sensor_columns]\n",
    "\n",
    "# Melt the DataFrame, excluding weather and other non-sensor columns\n",
    "df_melted = df_mergedsensors.melt(\n",
    "    id_vars=[\n",
    "        'Time', 'Temperature (°C)', 'Relative Humidity (%)', 'Precipitation (mm)', \n",
    "        'Wind Speed (km/h)', 'Sunshine Duration (min)', 'Tag', 'Monat', 'Jahr', \n",
    "        'Wochentag', 'Wochenende', 'Jahreszeit', 'Laubfärbung', 'Besuchszahlen_HEH', \n",
    "        'Besuchszahlen_HZW', 'Besuchszahlen_WGM', 'Parkpl_HEH_PKW', 'Parkpl_HEH_BUS', \n",
    "        'Parkpl_HZW_PKW', 'Parkpl_HZW_BUS', 'Schulferien_Bayern', 'Schulferien_CZ', \n",
    "        'Feiertag_Bayern', 'Feiertag_CZ', 'HEH_geoeffnet', 'HZW_geoeffnet', 'WGM_geoeffnet', \n",
    "        'Lusenschutzhaus_geoeffnet', 'Racheldiensthuette_geoeffnet', 'Waldschmidthaus_geoeffnet', \n",
    "        'Falkensteinschutzhaus_geoeffnet', 'Schwellhaeusl_geoeffnet', 'Temperatur', \n",
    "        'Niederschlagsmenge', 'Schneehoehe', 'GS mit', 'GS max'\n",
    "    ],\n",
    "    value_vars=melt_columns,\n",
    "    var_name='Sensor_Direction',\n",
    "    value_name='Count'\n",
    ")\n",
    "\n",
    "# Split the Sensor_Direction into separate Sensor Name and Direction columns\n",
    "df_melted[['Sensor', 'Direction']] = df_melted['Sensor_Direction'].str.rsplit(' ', n=1, expand=True)\n",
    "df_melted.drop(columns=['Sensor_Direction'], inplace=True)\n",
    "\n",
    "# Extract hour from the 'Time' column\n",
    "df_melted['Hour'] = df_melted['Time'].dt.hour\n",
    "\n",
    "# Pivot the DataFrame to have 'IN' and 'OUT' as separate columns, while retaining hour in the rows\n",
    "df_pivot = df_melted.pivot_table(\n",
    "    index=['Time', 'Sensor', 'Hour'], \n",
    "    columns='Direction', \n",
    "    values='Count',\n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "# Merge the original non-sensor columns back to the pivoted DataFrame\n",
    "# Exclude the columns that have been pivoted to avoid duplication\n",
    "non_sensor_columns = [\n",
    "    'Time', 'Temperature (°C)', 'Relative Humidity (%)', 'Precipitation (mm)', \n",
    "    'Wind Speed (km/h)', 'Sunshine Duration (min)', 'Tag', 'Monat', 'Jahr', \n",
    "    'Wochentag', 'Wochenende', 'Jahreszeit', 'Laubfärbung', 'Besuchszahlen_HEH', \n",
    "    'Besuchszahlen_HZW', 'Besuchszahlen_WGM', 'Parkpl_HEH_PKW', 'Parkpl_HEH_BUS', \n",
    "    'Parkpl_HZW_PKW', 'Parkpl_HZW_BUS', 'Schulferien_Bayern', 'Schulferien_CZ', \n",
    "    'Feiertag_Bayern', 'Feiertag_CZ', 'HEH_geoeffnet', 'HZW_geoeffnet', 'WGM_geoeffnet', \n",
    "    'Lusenschutzhaus_geoeffnet', 'Racheldiensthuette_geoeffnet', 'Waldschmidthaus_geoeffnet', \n",
    "    'Falkensteinschutzhaus_geoeffnet', 'Schwellhaeusl_geoeffnet', 'Temperatur', \n",
    "    'Niederschlagsmenge', 'Schneehoehe', 'GS mit', 'GS max'\n",
    "]\n",
    "\n",
    "# Merge back the non-sensor columns using 'Time' as the key\n",
    "df_final = pd.merge(df_pivot, df_mergedsensors[non_sensor_columns], on='Time', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns by specifying the new names\n",
    "df_final = df_final.rename(columns={\n",
    "    'Temperature (°C)': 'Temperature',\n",
    "    'Relative Humidity (%)': 'Relative Humidity',\n",
    "    'Precipitation (mm)': 'Precipitation',\n",
    "    'Wind Speed (km/h)': 'Wind Speed',\n",
    "    'Sunshine Duration (min)': 'Sunshine Duration'\n",
    "})\n",
    "\n",
    "# Print the renamed columns to verify\n",
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sensor_loc variable\n",
    "\n",
    "# Create a dictionary for mapping\n",
    "location_mapping = {\n",
    "    'Bayerisch Eisenstein': 'North', 'Brechhäuslau': 'North', 'Deffernik': 'North', \n",
    "    'Falkenstein 1': 'North', 'Falkenstein 2': 'North', 'Ferdinandsthal': 'North', \n",
    "    'Gsenget': 'North', 'Scheuereck': 'North', 'Schillerstraße': 'North', \n",
    "    'Trinkwassertalsperre': 'North', 'Bucina': 'South', 'Diensthüttenstraße': 'South', \n",
    "    'Felswandergebiet': 'South', 'Fredenbrücke': 'South', 'Gfäll': 'South', \n",
    "    'Klingenbrunner Wald': 'South', 'Klosterfilz': 'South', 'Lusen 1': 'South', \n",
    "    'Lusen 2': 'South', 'Lusen 3': 'South', 'Racheldiensthütte': 'South', \n",
    "    'Schwarzbachbrücke': 'South', 'Waldhausreibe': 'South', 'Waldspielgelände': 'South', \n",
    "    'Wistlberg': 'South', 'Sagwassersäge': 'South'\n",
    "}\n",
    "\n",
    "# Assign values to the new column 'Sensor_loc'\n",
    "df_final['Sensor_loc'] = df_final['Sensor'].map(location_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Traffic Absolute Variable\n",
    "df_final['Traffic_ABS'] = df_final['IN'] + df_final['OUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_sub = df_final[df_final['Jahr'].isin([2023, 2024])].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min and max values of Traffic_ABS in df_final_filtered\n",
    "min_value = df_final_sub['Traffic_ABS'].min()\n",
    "max_value = df_final_sub['Traffic_ABS'].max()\n",
    "\n",
    "# Apply min-max normalization to create the Traffic_NORM column\n",
    "df_final_sub['Traffic_NORM'] = (df_final_sub['Traffic_ABS'] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_sub['Pred_Traffic_ABS'] = pd.NA\n",
    "df_final_sub['Pred_Traffic_NORM'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_sub['Wochentag'] = df_final_sub['Wochentag'].astype('category')\n",
    "df_final_sub['Jahreszeit'] = df_final_sub['Jahreszeit'].astype('category')\n",
    "df_final_sub['Schulferien_CZ'] = df_final_sub['Jahreszeit'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces in column names with underscores\n",
    "df_final_sub.columns = df_final_sub.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping from German days to numbers\n",
    "day_mapping = {\n",
    "    'Sonntag': 1,\n",
    "    'Montag': 2,\n",
    "    'Dienstag': 3,\n",
    "    'Mittwoch': 4,\n",
    "    'Donnerstag': 5,\n",
    "    'Freitag': 6,\n",
    "    'Samstag': 7\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Wochentag column\n",
    "df_final_sub['Wochentag'] = df_final_sub['Wochentag'].map(day_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_final_sub.columns:\n",
    "    # Check if the column's data type is bool\n",
    "    if df_final_sub[column].dtype == 'bool':\n",
    "        # Convert True/False to 1/0\n",
    "        df_final_sub[column] = df_final_sub[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping from German days to numbers\n",
    "season_mapping = {\n",
    "    'Winter': 1,\n",
    "    'Frühling': 2,\n",
    "    'Sommer': 3,\n",
    "    'Herbst': 4\n",
    "}\n",
    "\n",
    "# Apply the mapping to the Wochentag column\n",
    "df_final_sub['Jahreszeit'] = df_final_sub['Jahreszeit'].map(season_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean features to integer (True=1, False=0)\n",
    "for bool_feature in bool_features:\n",
    "    data[bool_feature] = data[bool_feature].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data based on 'Jahr'\n",
    "train_data = df_final_sub[df_final_sub['Jahr'] == 2023]\n",
    "test_data = df_final_sub[df_final_sub['Jahr'] == 2024]\n",
    "\n",
    "# Define the features and target variable\n",
    "numeric_features = [\n",
    "    'Temperature',\n",
    "    'Relative_Humidity',\n",
    "    'Precipitation',\n",
    "    'Wind_Speed',\n",
    "    'Sunshine_Duration',\n",
    "]\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = [\n",
    "    'Monat', 'Wochentag', 'Jahreszeit'\n",
    "]\n",
    "\n",
    "# Identify bool features\n",
    "bool_features = [\n",
    "    'Wochenende', 'Laubfärbung', 'Schulferien_Bayern', 'Schulferien_CZ', 'Feiertag_Bayern', 'Feiertag_CZ',\n",
    "    'HEH_geoeffnet', 'HZW_geoeffnet', 'WGM_geoeffnet', 'Lusenschutzhaus_geoeffnet',\n",
    "    'Racheldiensthuette_geoeffnet', 'Falkensteinschutzhaus_geoeffnet', 'Schwellhaeusl_geoeffnet', 'Schulferien_CZ'\n",
    "]\n",
    "\n",
    "target = 'Traffic_ABS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Traffic_ABS ~ Temperature + Relative_Humidity + Precipitation + Wind_Speed + Sunshine_Duration + Wochenende\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your data into df_final_sub\n",
    "# df_final_sub = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Split the data based on 'Jahr'\n",
    "train_data = df_final_sub[df_final_sub['Jahr'] == 2023]\n",
    "test_data = df_final_sub[df_final_sub['Jahr'] == 2024]\n",
    "\n",
    "# Define features and target\n",
    "numeric_features = [\n",
    "    'Temperature',\n",
    "    'Relative_Humidity',\n",
    "    'Precipitation',\n",
    "    'Wind_Speed',\n",
    "    'Sunshine_Duration',\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Monat', 'Wochentag', 'Jahreszeit'\n",
    "]\n",
    "\n",
    "bool_features = [\n",
    "    'Wochenende', 'Laubfärbung', 'Schulferien_Bayern', 'Schulferien_CZ', 'Feiertag_Bayern', 'Feiertag_CZ',\n",
    "    'HEH_geoeffnet', 'HZW_geoeffnet', 'WGM_geoeffnet', 'Lusenschutzhaus_geoeffnet',\n",
    "    'Racheldiensthuette_geoeffnet', 'Falkensteinschutzhaus_geoeffnet', 'Schwellhaeusl_geoeffnet', 'Schulferien_CZ'\n",
    "]\n",
    "\n",
    "target = 'Traffic_ABS'\n",
    "\n",
    "# Combine all features\n",
    "all_features = numeric_features + categorical_features + bool_features\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "        ('bool', 'passthrough', bool_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "X_train = train_data[all_features]\n",
    "y_train = train_data[target]\n",
    "\n",
    "# Transform features\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Create a DataFrame with transformed features\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed)\n",
    "\n",
    "# Define the mixed effects model\n",
    "# Assuming random intercepts for 'Jahr' as an example\n",
    "model = mixedlm(f\"{target} ~ {' + '.join(numeric_features + bool_features)}\", \n",
    "                 train_data,\n",
    "                 groups=train_data[\"Sensor\"],\n",
    "                 re_formula=\"~1\",\n",
    "                 vc_formula={\"Sensor\": \"0 + C(Sensor)\"})\n",
    "\n",
    "# Fit the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "# Prepare test data similarly\n",
    "X_test = test_data[all_features]\n",
    "y_test = test_data[target]\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "X_test_transformed_df = pd.DataFrame(X_test_transformed)\n",
    "\n",
    "# Make predictions (if needed)\n",
    "# predictions = result.predict(X_test_transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path where you want to save the file\n",
    "folder_path = \"\" # Define the path to the output folder\n",
    "\n",
    "# Combine the folder path and file name\n",
    "file_path = f'{folder_path}/rotated_sensors_data.csv'\n",
    "\n",
    "# Write the final DataFrame to a CSV file in the specified folder\n",
    "df_final_sub.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
