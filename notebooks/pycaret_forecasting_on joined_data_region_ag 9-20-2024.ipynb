{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.time_series import *\n",
    "from pycaret.regression import *\n",
    "import matplotlib.pyplot as plt\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "from pycaret import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from pycaret.regression import load_model, plot_model\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from meteostat import Hourly, Point\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(profile_name='anthony_garove_fellow_dssgx_24')\n",
    "\n",
    "bucket = \"dssgx-munich-2024-bavarian-forest\"\n",
    "raw_data_folder = \"raw-data\"\n",
    "preprocessed_data_folder = \"preprocessed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Schneehoehe</th>\n",
       "      <th>GS mit</th>\n",
       "      <th>GS max</th>\n",
       "      <th>Total</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Relative Humidity (%)</th>\n",
       "      <th>Precipitation (mm)</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Sunshine Duration (min)</th>\n",
       "      <th>coco_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-10 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-10 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-10 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-10 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-10 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "0  2016-05-10 03:00:00                      NaN                       NaN   \n",
       "1  2016-05-10 04:00:00                      NaN                       NaN   \n",
       "2  2016-05-10 05:00:00                      NaN                       NaN   \n",
       "3  2016-05-10 06:00:00                      NaN                       NaN   \n",
       "4  2016-05-10 07:00:00                      NaN                       NaN   \n",
       "\n",
       "   Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "0              2.0               0.0           NaN            NaN   \n",
       "1              0.0               0.0           NaN            NaN   \n",
       "2              0.0               0.0           NaN            NaN   \n",
       "3              0.0               0.0           NaN            NaN   \n",
       "4              0.0               9.0           NaN            NaN   \n",
       "\n",
       "   Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  ...  \\\n",
       "0                    NaN                     NaN                  NaN  ...   \n",
       "1                    NaN                     NaN                  NaN  ...   \n",
       "2                    NaN                     NaN                  NaN  ...   \n",
       "3                    NaN                     NaN                  NaN  ...   \n",
       "4                    NaN                     NaN                  NaN  ...   \n",
       "\n",
       "   Schneehoehe  GS mit  GS max  Total  Temperature (°C)  \\\n",
       "0          NaN     NaN     NaN    NaN               NaN   \n",
       "1          NaN     NaN     NaN    NaN               NaN   \n",
       "2          NaN     NaN     NaN    NaN               NaN   \n",
       "3          NaN     NaN     NaN    NaN               NaN   \n",
       "4          NaN     NaN     NaN    NaN               NaN   \n",
       "\n",
       "   Relative Humidity (%)  Precipitation (mm)  Wind Speed (km/h)  \\\n",
       "0                    NaN                 NaN                NaN   \n",
       "1                    NaN                 NaN                NaN   \n",
       "2                    NaN                 NaN                NaN   \n",
       "3                    NaN                 NaN                NaN   \n",
       "4                    NaN                 NaN                NaN   \n",
       "\n",
       "   Sunshine Duration (min)  coco_2  \n",
       "0                      NaN     NaN  \n",
       "1                      NaN     NaN  \n",
       "2                      NaN     NaN  \n",
       "3                      NaN     NaN  \n",
       "4                      NaN     NaN  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv_files_from_aws_s3(path: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Loads individual or multiple CSV files from an AWS S3 bucket.\n",
    "    Args:\n",
    "        path (str): The path to the CSV files on AWS S3.\n",
    "        **kwargs: Additional arguments to pass to the read_csv function.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the data from the CSV files.\n",
    "    \"\"\"\n",
    "    df = wr.s3.read_csv(path=path, **kwargs)\n",
    "    return df\n",
    "df = load_csv_files_from_aws_s3(\n",
    "    path=\"s3://dssgx-munich-2024-bavarian-forest/preprocessed_data/joined_sensor_weather_visitorcenter_2016-2024.csv\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Schneehoehe</th>\n",
       "      <th>GS mit</th>\n",
       "      <th>GS max</th>\n",
       "      <th>Total</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Relative Humidity (%)</th>\n",
       "      <th>Precipitation (mm)</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Sunshine Duration (min)</th>\n",
       "      <th>coco_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75784</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75785</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75786</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "75784  2024-12-31 19:00:00                      NaN                       NaN   \n",
       "75785  2024-12-31 20:00:00                      NaN                       NaN   \n",
       "75786  2024-12-31 21:00:00                      NaN                       NaN   \n",
       "75787  2024-12-31 22:00:00                      NaN                       NaN   \n",
       "75788  2024-12-31 23:00:00                      NaN                       NaN   \n",
       "\n",
       "       Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "75784              NaN               NaN           NaN            NaN   \n",
       "75785              NaN               NaN           NaN            NaN   \n",
       "75786              NaN               NaN           NaN            NaN   \n",
       "75787              NaN               NaN           NaN            NaN   \n",
       "75788              NaN               NaN           NaN            NaN   \n",
       "\n",
       "       Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "75784                    NaN                     NaN                  NaN   \n",
       "75785                    NaN                     NaN                  NaN   \n",
       "75786                    NaN                     NaN                  NaN   \n",
       "75787                    NaN                     NaN                  NaN   \n",
       "75788                    NaN                     NaN                  NaN   \n",
       "\n",
       "       ...  Schneehoehe  GS mit  GS max  Total  Temperature (°C)  \\\n",
       "75784  ...          NaN     NaN     NaN    1.0               NaN   \n",
       "75785  ...          NaN     NaN     NaN    1.0               NaN   \n",
       "75786  ...          NaN     NaN     NaN    1.0               NaN   \n",
       "75787  ...          NaN     NaN     NaN    1.0               NaN   \n",
       "75788  ...          NaN     NaN     NaN    1.0               NaN   \n",
       "\n",
       "       Relative Humidity (%)  Precipitation (mm)  Wind Speed (km/h)  \\\n",
       "75784                    NaN                 NaN                NaN   \n",
       "75785                    NaN                 NaN                NaN   \n",
       "75786                    NaN                 NaN                NaN   \n",
       "75787                    NaN                 NaN                NaN   \n",
       "75788                    NaN                 NaN                NaN   \n",
       "\n",
       "       Sunshine Duration (min)  coco_2  \n",
       "75784                      NaN     NaN  \n",
       "75785                      NaN     NaN  \n",
       "75786                      NaN     NaN  \n",
       "75787                      NaN     NaN  \n",
       "75788                      NaN     NaN  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to use\n",
    "columns_to_use = [\n",
    "'Time',  'Bayerisch Eisenstein IN',  'Bayerisch Eisenstein OUT',  'Brechhäuslau IN',  'Brechhäuslau OUT',  \n",
    "'Deffernik IN',  'Deffernik OUT',  'Diensthüttenstraße IN',  'Diensthüttenstraße OUT',  'Felswandergebiet IN',  \n",
    "'Felswandergebiet OUT',  'Ferdinandsthal IN',  'Ferdinandsthal OUT',  'Fredenbrücke IN',  'Fredenbrücke OUT',  \n",
    "'Gfäll IN',  'Gfäll OUT',  'Gsenget IN',  'Gsenget OUT',  'Klingenbrunner Wald IN',  'Klingenbrunner Wald OUT',  \n",
    "'Klosterfilz IN',  'Klosterfilz OUT',  'Racheldiensthütte IN',  'Racheldiensthütte OUT',  'Sagwassersäge IN',  \n",
    "'Sagwassersäge OUT',  'Scheuereck IN',  'Scheuereck OUT',  'Schillerstraße IN',  'Schillerstraße OUT',  \n",
    "'Schwarzbachbrücke IN',  'Schwarzbachbrücke OUT',  'Falkenstein 2 OUT',  'Falkenstein 2 IN',  'Lusen 2 IN',  \n",
    "'Lusen 2 OUT',  'Lusen 3 IN',  'Lusen 3 OUT',  'Waldhausreibe IN',  'Waldhausreibe OUT',  'Waldspielgelände IN',  \n",
    "'Waldspielgelände OUT',  'Wistlberg IN',  'Wistlberg OUT',  'Bucina MERGED IN',  'Bucina MERGED OUT',  \n",
    "'Falkenstein 1 MERGED IN',  'Falkenstein 1 MERGED OUT',  'Lusen 1 MERGED IN',  'Lusen 1 MERGED OUT',  \n",
    "'Trinkwassertalsperre MERGED IN',  'Trinkwassertalsperre MERGED OUT',  \n",
    "'traffic_abs',  'sum_IN_abs',  'sum_OUT_abs',  'Temperature (°C)',  'Relative Humidity (%)',  \n",
    "'Wind Speed (km/h)', 'Tag',  'Monat', 'Wochentag',  'Wochenende',  'Jahreszeit',  'Laubfärbung',  'Schulferien_Bayern',  \n",
    "'Schulferien_CZ', 'Feiertag_Bayern',  'Feiertag_CZ',  'HEH_geoeffnet',  'HZW_geoeffnet',  'WGM_geoeffnet',  \n",
    "'Lusenschutzhaus_geoeffnet',  'Racheldiensthuette_geoeffnet',  'Falkensteinschutzhaus_geoeffnet',  \n",
    "'Schwellhaeusl_geoeffnet'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Schulferien_CZ</th>\n",
       "      <th>Feiertag_Bayern</th>\n",
       "      <th>Feiertag_CZ</th>\n",
       "      <th>HEH_geoeffnet</th>\n",
       "      <th>HZW_geoeffnet</th>\n",
       "      <th>WGM_geoeffnet</th>\n",
       "      <th>Lusenschutzhaus_geoeffnet</th>\n",
       "      <th>Racheldiensthuette_geoeffnet</th>\n",
       "      <th>Falkensteinschutzhaus_geoeffnet</th>\n",
       "      <th>Schwellhaeusl_geoeffnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75784</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75785</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75786</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "75784  2024-12-31 19:00:00                      NaN                       NaN   \n",
       "75785  2024-12-31 20:00:00                      NaN                       NaN   \n",
       "75786  2024-12-31 21:00:00                      NaN                       NaN   \n",
       "75787  2024-12-31 22:00:00                      NaN                       NaN   \n",
       "75788  2024-12-31 23:00:00                      NaN                       NaN   \n",
       "\n",
       "       Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "75784              NaN               NaN           NaN            NaN   \n",
       "75785              NaN               NaN           NaN            NaN   \n",
       "75786              NaN               NaN           NaN            NaN   \n",
       "75787              NaN               NaN           NaN            NaN   \n",
       "75788              NaN               NaN           NaN            NaN   \n",
       "\n",
       "       Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "75784                    NaN                     NaN                  NaN   \n",
       "75785                    NaN                     NaN                  NaN   \n",
       "75786                    NaN                     NaN                  NaN   \n",
       "75787                    NaN                     NaN                  NaN   \n",
       "75788                    NaN                     NaN                  NaN   \n",
       "\n",
       "       ...  Schulferien_CZ  Feiertag_Bayern  Feiertag_CZ  HEH_geoeffnet  \\\n",
       "75784  ...            True             True        False           True   \n",
       "75785  ...            True             True        False           True   \n",
       "75786  ...            True             True        False           True   \n",
       "75787  ...            True             True        False           True   \n",
       "75788  ...            True             True        False           True   \n",
       "\n",
       "       HZW_geoeffnet  WGM_geoeffnet  Lusenschutzhaus_geoeffnet  \\\n",
       "75784           True           True                       True   \n",
       "75785           True           True                       True   \n",
       "75786           True           True                       True   \n",
       "75787           True           True                       True   \n",
       "75788           True           True                       True   \n",
       "\n",
       "       Racheldiensthuette_geoeffnet  Falkensteinschutzhaus_geoeffnet  \\\n",
       "75784                          True                             True   \n",
       "75785                          True                             True   \n",
       "75786                          True                             True   \n",
       "75787                          True                             True   \n",
       "75788                          True                             True   \n",
       "\n",
       "       Schwellhaeusl_geoeffnet  \n",
       "75784                     True  \n",
       "75785                     True  \n",
       "75786                     True  \n",
       "75787                     True  \n",
       "75788                     True  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe to only include the specified columns\n",
    "df = df[columns_to_use]\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Nationalparkzentrum Lusen IN</th>\n",
       "      <th>Nationalparkzentrum Lusen OUT</th>\n",
       "      <th>Falkenstein-Schwellhäusl IN</th>\n",
       "      <th>Falkenstein-Schwellhäusl OUT</th>\n",
       "      <th>Rachel-Spiegelau IN</th>\n",
       "      <th>Rachel-Spiegelau OUT</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre IN</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre OUT</th>\n",
       "      <th>Lusen-Mauth-Finsterau IN</th>\n",
       "      <th>Lusen-Mauth-Finsterau OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75784</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75785</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75786</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "75784  2024-12-31 19:00:00                      NaN                       NaN   \n",
       "75785  2024-12-31 20:00:00                      NaN                       NaN   \n",
       "75786  2024-12-31 21:00:00                      NaN                       NaN   \n",
       "75787  2024-12-31 22:00:00                      NaN                       NaN   \n",
       "75788  2024-12-31 23:00:00                      NaN                       NaN   \n",
       "\n",
       "       Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "75784              NaN               NaN           NaN            NaN   \n",
       "75785              NaN               NaN           NaN            NaN   \n",
       "75786              NaN               NaN           NaN            NaN   \n",
       "75787              NaN               NaN           NaN            NaN   \n",
       "75788              NaN               NaN           NaN            NaN   \n",
       "\n",
       "       Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "75784                    NaN                     NaN                  NaN   \n",
       "75785                    NaN                     NaN                  NaN   \n",
       "75786                    NaN                     NaN                  NaN   \n",
       "75787                    NaN                     NaN                  NaN   \n",
       "75788                    NaN                     NaN                  NaN   \n",
       "\n",
       "       ...  Nationalparkzentrum Lusen IN  Nationalparkzentrum Lusen OUT  \\\n",
       "75784  ...                           NaN                            NaN   \n",
       "75785  ...                           NaN                            NaN   \n",
       "75786  ...                           NaN                            NaN   \n",
       "75787  ...                           NaN                            NaN   \n",
       "75788  ...                           NaN                            NaN   \n",
       "\n",
       "       Falkenstein-Schwellhäusl IN  Falkenstein-Schwellhäusl OUT  \\\n",
       "75784                          NaN                           NaN   \n",
       "75785                          NaN                           NaN   \n",
       "75786                          NaN                           NaN   \n",
       "75787                          NaN                           NaN   \n",
       "75788                          NaN                           NaN   \n",
       "\n",
       "       Rachel-Spiegelau IN  Rachel-Spiegelau OUT  \\\n",
       "75784                  NaN                   NaN   \n",
       "75785                  NaN                   NaN   \n",
       "75786                  NaN                   NaN   \n",
       "75787                  NaN                   NaN   \n",
       "75788                  NaN                   NaN   \n",
       "\n",
       "       Scheuereck-Schachten-Trinkwassertalsperre IN  \\\n",
       "75784                                           NaN   \n",
       "75785                                           NaN   \n",
       "75786                                           NaN   \n",
       "75787                                           NaN   \n",
       "75788                                           NaN   \n",
       "\n",
       "       Scheuereck-Schachten-Trinkwassertalsperre OUT  \\\n",
       "75784                                            NaN   \n",
       "75785                                            NaN   \n",
       "75786                                            NaN   \n",
       "75787                                            NaN   \n",
       "75788                                            NaN   \n",
       "\n",
       "       Lusen-Mauth-Finsterau IN  Lusen-Mauth-Finsterau OUT  \n",
       "75784                       NaN                        NaN  \n",
       "75785                       NaN                        NaN  \n",
       "75786                       NaN                        NaN  \n",
       "75787                       NaN                        NaN  \n",
       "75788                       NaN                        NaN  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE NEW REGION VARIABLE\n",
    "\n",
    "# Remove MERGED from column names with this unnecessary label\n",
    "df.columns = df.columns.str.replace(' MERGED', '', regex=False)\n",
    "\n",
    "# Create a dictionary for mapping\n",
    "location_mapping = {\n",
    "    'Bayerisch Eisenstein IN': 'Falkenstein-Schwellhäusl',\n",
    "    'Bayerisch Eisenstein OUT': 'Falkenstein-Schwellhäusl', \n",
    "    'Brechhäuslau IN': 'Falkenstein-Schwellhäusl', \n",
    "    'Brechhäuslau OUT': 'Falkenstein-Schwellhäusl', \n",
    "    'Deffernik IN': 'Falkenstein-Schwellhäusl',\n",
    "    'Deffernik OUT': 'Falkenstein-Schwellhäusl',\n",
    "    'Falkenstein 1 IN': 'Nationalparkzentrum Falkenstein', \n",
    "    'Falkenstein 1 OUT': 'Nationalparkzentrum Falkenstein',\n",
    "    'Falkenstein 2 IN': 'Nationalparkzentrum Falkenstein', \n",
    "    'Falkenstein 2 OUT': 'Nationalparkzentrum Falkenstein',\n",
    "    'Ferdinandsthal IN': 'Falkenstein-Schwellhäusl', \n",
    "    'Ferdinandsthal OUT': 'Falkenstein-Schwellhäusl', \n",
    "    'Gsenget IN': 'Scheuereck-Schachten-Trinkwassertalsperre', \n",
    "    'Gsenget OUT': 'Scheuereck-Schachten-Trinkwassertalsperre', \n",
    "    'Scheuereck IN': 'Scheuereck-Schachten-Trinkwassertalsperre',\n",
    "    'Scheuereck OUT': 'Scheuereck-Schachten-Trinkwassertalsperre', \n",
    "    'Schillerstraße IN': 'Falkenstein-Schwellhäusl', \n",
    "    'Schillerstraße OUT': 'Falkenstein-Schwellhäusl', \n",
    "    'Trinkwassertalsperre IN': 'Scheuereck-Schachten-Trinkwassertalsperre',\n",
    "    'Trinkwassertalsperre OUT': 'Scheuereck-Schachten-Trinkwassertalsperre',\n",
    "    'Bucina IN': 'Lusen-Mauth-Finsterau',\n",
    "    'Bucina OUT': 'Lusen-Mauth-Finsterau', \n",
    "    'Diensthüttenstraße IN': 'Rachel-Spiegelau', \n",
    "    'Diensthüttenstraße OUT': 'Rachel-Spiegelau',\n",
    "    'Felswandergebiet IN': 'Lusen-Mauth-Finsterau', \n",
    "    'Felswandergebiet OUT': 'Lusen-Mauth-Finsterau',\n",
    "    'Fredenbrücke IN': 'Lusen-Mauth-Finsterau', \n",
    "    'Fredenbrücke OUT': 'Lusen-Mauth-Finsterau', \n",
    "    'Gfäll IN': 'Rachel-Spiegelau', \n",
    "    'Gfäll OUT': 'Rachel-Spiegelau', \n",
    "    'Klingenbrunner Wald IN': 'Rachel-Spiegelau', \n",
    "    'Klingenbrunner Wald OUT': 'Rachel-Spiegelau', \n",
    "    'Klosterfilz IN': 'Rachel-Spiegelau', \n",
    "    'Klosterfilz OUT': 'Rachel-Spiegelau',\n",
    "    'Lusen 1 IN': 'Nationalparkzentrum Lusen', \n",
    "    'Lusen 1 OUT': 'Nationalparkzentrum Lusen', \n",
    "    'Lusen 2 IN': 'Nationalparkzentrum Lusen',\n",
    "    'Lusen 2 OUT': 'Nationalparkzentrum Lusen', \n",
    "    'Lusen 3 IN': 'Nationalparkzentrum Lusen', \n",
    "    'Lusen 3 OUT': 'Nationalparkzentrum Lusen',\n",
    "    'Racheldiensthütte IN': 'Rachel-Spiegelau', \n",
    "    'Racheldiensthütte OUT': 'Rachel-Spiegelau',\n",
    "    'Schwarzbachbrücke IN': 'Lusen-Mauth-Finsterau', \n",
    "    'Schwarzbachbrücke OUT': 'Lusen-Mauth-Finsterau', \n",
    "    'Waldhausreibe IN': 'Lusen-Mauth-Finsterau', \n",
    "    'Waldhausreibe OUT': 'Lusen-Mauth-Finsterau', \n",
    "    'Waldspielgelände IN': 'Rachel-Spiegelau', \n",
    "    'Waldspielgelände OUT': 'Rachel-Spiegelau', \n",
    "    'Wistlberg IN': 'Lusen-Mauth-Finsterau', \n",
    "    'Wistlberg OUT': 'Lusen-Mauth-Finsterau', \n",
    "    'Sagwassersäge IN': 'Lusen-Mauth-Finsterau',\n",
    "    'Sagwassersäge OUT': 'Lusen-Mauth-Finsterau'\n",
    "}\n",
    "\n",
    "# Extract unique regions\n",
    "regions = set(location_mapping.values())\n",
    "\n",
    "# Iterate over each region\n",
    "for region in regions:\n",
    "    # Filter the keys in location_mapping that belong to the current region\n",
    "    region_in_columns = [col for col in location_mapping if location_mapping[col] == region and ' IN' in col]\n",
    "    region_out_columns = [col for col in location_mapping if location_mapping[col] == region and ' OUT' in col]\n",
    "\n",
    "    # Sum the values for all IN columns of the current region, while retaining NaN where all are NaN\n",
    "    df[f'{region} IN'] = df[region_in_columns].sum(axis=1, min_count=1)\n",
    "    \n",
    "    # Sum the values for all OUT columns of the current region, while retaining NaN where all are NaN\n",
    "    df[f'{region} OUT'] = df[region_out_columns].sum(axis=1, min_count=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.tail()\n",
    "\n",
    "# EXPLANATION OF LOOPING FUNCTION BELOW\n",
    "#min_count=1 in sum():\n",
    "#The sum(axis=1, min_count=1) method ensures that if all values being summed are NaN, the result will be NaN.\n",
    "#If at least one value is not NaN, it will compute the sum, ignoring the NaN values.\n",
    "#Explanation:\n",
    "#min_count=1: This parameter in the sum() function specifies the minimum number of non-NaN values required to perform the summation. If the count of non-NaN values is less than min_count, the result will be NaN.\n",
    "#Result: The DataFrame will have the new region columns that sum the sensors while retaining NaN if all sensors in a region are NaN for a given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Sunshine Duration (min)</th>\n",
       "      <th>coco_2</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance_to_Nearest_Holiday_Bayern</th>\n",
       "      <th>Distance_to_Nearest_Holiday_CZ</th>\n",
       "      <th>ZScore_Daily_Max_Temperature (°C)</th>\n",
       "      <th>ZScore_Daily_Max_Relative Humidity (%)</th>\n",
       "      <th>ZScore_Daily_Max_Precipitation (mm)</th>\n",
       "      <th>ZScore_Daily_Max_Wind Speed (km/h)</th>\n",
       "      <th>ZScore_Daily_Max_Sunshine Duration (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "0  2017-01-01 00:00:00                      NaN                       NaN   \n",
       "1  2017-01-01 01:00:00                      NaN                       NaN   \n",
       "2  2017-01-01 02:00:00                      NaN                       NaN   \n",
       "3  2017-01-01 03:00:00                      NaN                       NaN   \n",
       "4  2017-01-01 04:00:00                      NaN                       NaN   \n",
       "\n",
       "   Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "0            257.0             412.0           NaN            NaN   \n",
       "1              NaN               NaN           NaN            NaN   \n",
       "2              NaN               NaN           NaN            NaN   \n",
       "3              NaN               NaN           NaN            NaN   \n",
       "4              NaN               NaN           NaN            NaN   \n",
       "\n",
       "   Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  ...  \\\n",
       "0                    NaN                     NaN                  NaN  ...   \n",
       "1                    NaN                     NaN                  NaN  ...   \n",
       "2                    NaN                     NaN                  NaN  ...   \n",
       "3                    NaN                     NaN                  NaN  ...   \n",
       "4                    NaN                     NaN                  NaN  ...   \n",
       "\n",
       "   Sunshine Duration (min)  coco_2        Date  \\\n",
       "0                      0.0     NaN  2017-01-01   \n",
       "1                      0.0     NaN  2017-01-01   \n",
       "2                      0.0     NaN  2017-01-01   \n",
       "3                      0.0     NaN  2017-01-01   \n",
       "4                      0.0     NaN  2017-01-01   \n",
       "\n",
       "   Distance_to_Nearest_Holiday_Bayern  Distance_to_Nearest_Holiday_CZ  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "\n",
       "   ZScore_Daily_Max_Temperature (°C)  ZScore_Daily_Max_Relative Humidity (%)  \\\n",
       "0                                NaN                                     NaN   \n",
       "1                                NaN                                     NaN   \n",
       "2                                NaN                                     NaN   \n",
       "3                                NaN                                     NaN   \n",
       "4                                NaN                                     NaN   \n",
       "\n",
       "   ZScore_Daily_Max_Precipitation (mm)  ZScore_Daily_Max_Wind Speed (km/h)  \\\n",
       "0                                  NaN                                 NaN   \n",
       "1                                  NaN                                 NaN   \n",
       "2                                  NaN                                 NaN   \n",
       "3                                  NaN                                 NaN   \n",
       "4                                  NaN                                 NaN   \n",
       "\n",
       "   ZScore_Daily_Max_Sunshine Duration (min)  \n",
       "0                                       NaN  \n",
       "1                                       NaN  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_csv_files_from_aws_s3(path: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Loads individual or multiple CSV files from an AWS S3 bucket.\n",
    "    Args:\n",
    "        path (str): The path to the CSV files on AWS S3.\n",
    "        **kwargs: Additional arguments to pass to the read_csv function.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the data from the CSV files.\n",
    "    \"\"\"\n",
    "    df = wr.s3.read_csv(path=path, **kwargs)\n",
    "    return df\n",
    "df_newfeatures = load_csv_files_from_aws_s3(\n",
    "    path=\"s3://dssgx-munich-2024-bavarian-forest/preprocessed_data/holidays_deltaweather_features_df.csv\"\n",
    ")\n",
    "df_newfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Rachel-Spiegelau OUT</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre IN</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre OUT</th>\n",
       "      <th>Lusen-Mauth-Finsterau IN</th>\n",
       "      <th>Lusen-Mauth-Finsterau OUT</th>\n",
       "      <th>ZScore_Daily_Max_Temperature (°C)</th>\n",
       "      <th>ZScore_Daily_Max_Relative Humidity (%)</th>\n",
       "      <th>ZScore_Daily_Max_Wind Speed (km/h)</th>\n",
       "      <th>Distance_to_Nearest_Holiday_Bayern</th>\n",
       "      <th>Distance_to_Nearest_Holiday_CZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75784</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75785</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75786</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "75784 2024-12-31 19:00:00                      NaN                       NaN   \n",
       "75785 2024-12-31 20:00:00                      NaN                       NaN   \n",
       "75786 2024-12-31 21:00:00                      NaN                       NaN   \n",
       "75787 2024-12-31 22:00:00                      NaN                       NaN   \n",
       "75788 2024-12-31 23:00:00                      NaN                       NaN   \n",
       "\n",
       "       Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "75784              NaN               NaN           NaN            NaN   \n",
       "75785              NaN               NaN           NaN            NaN   \n",
       "75786              NaN               NaN           NaN            NaN   \n",
       "75787              NaN               NaN           NaN            NaN   \n",
       "75788              NaN               NaN           NaN            NaN   \n",
       "\n",
       "       Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "75784                    NaN                     NaN                  NaN   \n",
       "75785                    NaN                     NaN                  NaN   \n",
       "75786                    NaN                     NaN                  NaN   \n",
       "75787                    NaN                     NaN                  NaN   \n",
       "75788                    NaN                     NaN                  NaN   \n",
       "\n",
       "       ...  Rachel-Spiegelau OUT  \\\n",
       "75784  ...                   NaN   \n",
       "75785  ...                   NaN   \n",
       "75786  ...                   NaN   \n",
       "75787  ...                   NaN   \n",
       "75788  ...                   NaN   \n",
       "\n",
       "       Scheuereck-Schachten-Trinkwassertalsperre IN  \\\n",
       "75784                                           NaN   \n",
       "75785                                           NaN   \n",
       "75786                                           NaN   \n",
       "75787                                           NaN   \n",
       "75788                                           NaN   \n",
       "\n",
       "       Scheuereck-Schachten-Trinkwassertalsperre OUT  \\\n",
       "75784                                            NaN   \n",
       "75785                                            NaN   \n",
       "75786                                            NaN   \n",
       "75787                                            NaN   \n",
       "75788                                            NaN   \n",
       "\n",
       "       Lusen-Mauth-Finsterau IN  Lusen-Mauth-Finsterau OUT  \\\n",
       "75784                       NaN                        NaN   \n",
       "75785                       NaN                        NaN   \n",
       "75786                       NaN                        NaN   \n",
       "75787                       NaN                        NaN   \n",
       "75788                       NaN                        NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Temperature (°C)  \\\n",
       "75784                                NaN   \n",
       "75785                                NaN   \n",
       "75786                                NaN   \n",
       "75787                                NaN   \n",
       "75788                                NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Relative Humidity (%)  \\\n",
       "75784                                     NaN   \n",
       "75785                                     NaN   \n",
       "75786                                     NaN   \n",
       "75787                                     NaN   \n",
       "75788                                     NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Wind Speed (km/h)  Distance_to_Nearest_Holiday_Bayern  \\\n",
       "75784                                 NaN                                 0.0   \n",
       "75785                                 NaN                                 0.0   \n",
       "75786                                 NaN                                 0.0   \n",
       "75787                                 NaN                                 0.0   \n",
       "75788                                 NaN                                 0.0   \n",
       "\n",
       "       Distance_to_Nearest_Holiday_CZ  \n",
       "75784                             5.0  \n",
       "75785                             5.0  \n",
       "75786                             5.0  \n",
       "75787                             5.0  \n",
       "75788                             5.0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df_newfeatures['Time'] = pd.to_datetime(df_newfeatures['Time'])\n",
    "\n",
    "# Step 2: Select the columns you want to add from df_newfeatures\n",
    "columns_to_add = [\n",
    "    'ZScore_Daily_Max_Temperature (°C)',\n",
    "    'ZScore_Daily_Max_Relative Humidity (%)',\n",
    "    'ZScore_Daily_Max_Wind Speed (km/h)',\n",
    "    'Distance_to_Nearest_Holiday_Bayern',\n",
    "    'Distance_to_Nearest_Holiday_CZ'\n",
    "]\n",
    "\n",
    "# Ensure that the selected columns exist in df_newfeatures\n",
    "selected_columns = [col for col in columns_to_add if col in df_newfeatures.columns]\n",
    "\n",
    "# Step 3: Merge df with df_newfeatures on 'Time' and add the selected columns\n",
    "df = pd.merge(df, df_newfeatures[['Time'] + selected_columns], on='Time', how='left')\n",
    "\n",
    "# Optionally, you can display the merged dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>...</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre IN</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre OUT</th>\n",
       "      <th>Lusen-Mauth-Finsterau IN</th>\n",
       "      <th>Lusen-Mauth-Finsterau OUT</th>\n",
       "      <th>ZScore_Daily_Max_Temperature (°C)</th>\n",
       "      <th>ZScore_Daily_Max_Relative Humidity (%)</th>\n",
       "      <th>ZScore_Daily_Max_Wind Speed (km/h)</th>\n",
       "      <th>Distance_to_Nearest_Holiday_Bayern</th>\n",
       "      <th>Distance_to_Nearest_Holiday_CZ</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75784</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75785</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75786</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75787</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time  Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "75784 2024-12-31 19:00:00                      NaN                       NaN   \n",
       "75785 2024-12-31 20:00:00                      NaN                       NaN   \n",
       "75786 2024-12-31 21:00:00                      NaN                       NaN   \n",
       "75787 2024-12-31 22:00:00                      NaN                       NaN   \n",
       "75788 2024-12-31 23:00:00                      NaN                       NaN   \n",
       "\n",
       "       Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  Deffernik OUT  \\\n",
       "75784              NaN               NaN           NaN            NaN   \n",
       "75785              NaN               NaN           NaN            NaN   \n",
       "75786              NaN               NaN           NaN            NaN   \n",
       "75787              NaN               NaN           NaN            NaN   \n",
       "75788              NaN               NaN           NaN            NaN   \n",
       "\n",
       "       Diensthüttenstraße IN  Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "75784                    NaN                     NaN                  NaN   \n",
       "75785                    NaN                     NaN                  NaN   \n",
       "75786                    NaN                     NaN                  NaN   \n",
       "75787                    NaN                     NaN                  NaN   \n",
       "75788                    NaN                     NaN                  NaN   \n",
       "\n",
       "       ...  Scheuereck-Schachten-Trinkwassertalsperre IN  \\\n",
       "75784  ...                                           NaN   \n",
       "75785  ...                                           NaN   \n",
       "75786  ...                                           NaN   \n",
       "75787  ...                                           NaN   \n",
       "75788  ...                                           NaN   \n",
       "\n",
       "       Scheuereck-Schachten-Trinkwassertalsperre OUT  \\\n",
       "75784                                            NaN   \n",
       "75785                                            NaN   \n",
       "75786                                            NaN   \n",
       "75787                                            NaN   \n",
       "75788                                            NaN   \n",
       "\n",
       "       Lusen-Mauth-Finsterau IN  Lusen-Mauth-Finsterau OUT  \\\n",
       "75784                       NaN                        NaN   \n",
       "75785                       NaN                        NaN   \n",
       "75786                       NaN                        NaN   \n",
       "75787                       NaN                        NaN   \n",
       "75788                       NaN                        NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Temperature (°C)  \\\n",
       "75784                                NaN   \n",
       "75785                                NaN   \n",
       "75786                                NaN   \n",
       "75787                                NaN   \n",
       "75788                                NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Relative Humidity (%)  \\\n",
       "75784                                     NaN   \n",
       "75785                                     NaN   \n",
       "75786                                     NaN   \n",
       "75787                                     NaN   \n",
       "75788                                     NaN   \n",
       "\n",
       "       ZScore_Daily_Max_Wind Speed (km/h)  Distance_to_Nearest_Holiday_Bayern  \\\n",
       "75784                                 NaN                                 0.0   \n",
       "75785                                 NaN                                 0.0   \n",
       "75786                                 NaN                                 0.0   \n",
       "75787                                 NaN                                 0.0   \n",
       "75788                                 NaN                                 0.0   \n",
       "\n",
       "       Distance_to_Nearest_Holiday_CZ  Hour  \n",
       "75784                             5.0    19  \n",
       "75785                             5.0    20  \n",
       "75786                             5.0    21  \n",
       "75787                             5.0    22  \n",
       "75788                             5.0    23  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the data types\n",
    "dtype_dict = {\n",
    "    'Time': 'datetime64[ns]',\n",
    "    'traffic_abs': 'float64',\n",
    "    'Temperature (°C)': 'float64',\n",
    "    'Relative Humidity (%)': 'float64',\n",
    "    'Wind Speed (km/h)': 'float64',\n",
    "    'Monat': 'float64',\n",
    "    'Wochentag': 'category',\n",
    "    'Wochenende': 'category',\n",
    "    'Jahreszeit': 'category',\n",
    "    'Laubfärbung': 'category',\n",
    "    'Feiertag_Bayern': 'category',\n",
    "    'Feiertag_CZ': 'category',\n",
    "    'HEH_geoeffnet': 'category',\n",
    "    'HZW_geoeffnet': 'category',\n",
    "    'WGM_geoeffnet': 'category',\n",
    "    'Lusenschutzhaus_geoeffnet': 'category',\n",
    "    'Racheldiensthuette_geoeffnet': 'category',\n",
    "    'Falkensteinschutzhaus_geoeffnet': 'category',\n",
    "    'Schwellhaeusl_geoeffnet': 'category',\n",
    "    'Schulferien_Bayern': 'category',\n",
    "    'Schulferien_CZ': 'category',\n",
    "    'sum_IN_abs': 'float64',\n",
    "    'sum_OUT_abs': 'float64',\n",
    "    'Falkenstein-Schwellhäusl IN': 'float64',\n",
    "    'Rachel-Spiegelau IN': 'float64',\n",
    "    'Nationalparkzentrum Falkenstein IN': 'float64',\n",
    "    'Nationalparkzentrum Lusen IN': 'float64',\n",
    "    'Lusen-Mauth-Finsterau IN': 'float64',\n",
    "    'Scheuereck-Schachten-Trinkwassertalsperre IN': 'float64',\n",
    "    'Falkenstein-Schwellhäusl OUT': 'float64',\n",
    "    'Rachel-Spiegelau OUT': 'float64',\n",
    "    'Nationalparkzentrum Falkenstein OUT': 'float64',\n",
    "    'Nationalparkzentrum Lusen OUT': 'float64',\n",
    "    'Lusen-Mauth-Finsterau OUT': 'float64',\n",
    "    'Scheuereck-Schachten-Trinkwassertalsperre OUT': 'float64',\n",
    "    'Bayerisch Eisenstein IN': 'float64',\n",
    "    'Bayerisch Eisenstein OUT': 'float64',\n",
    "    'Brechhäuslau IN': 'float64',\n",
    "    'Brechhäuslau OUT': 'float64',\n",
    "    'Deffernik IN': 'float64',\n",
    "    'Deffernik OUT': 'float64',\n",
    "    'Diensthüttenstraße IN': 'float64',\n",
    "    'Diensthüttenstraße OUT': 'float64',\n",
    "    'Felswandergebiet IN': 'float64',\n",
    "    'Felswandergebiet OUT': 'float64',\n",
    "    'Ferdinandsthal IN': 'float64',\n",
    "    'Ferdinandsthal OUT': 'float64',\n",
    "    'Fredenbrücke IN': 'float64',\n",
    "    'Fredenbrücke OUT': 'float64',\n",
    "    'Gfäll IN': 'float64',\n",
    "    'Gfäll OUT': 'float64',\n",
    "    'Gsenget IN': 'float64',\n",
    "    'Gsenget OUT': 'float64',\n",
    "    'Klingenbrunner Wald IN': 'float64',\n",
    "    'Klingenbrunner Wald OUT': 'float64',\n",
    "    'Klosterfilz IN': 'float64',\n",
    "    'Klosterfilz OUT': 'float64',\n",
    "    'Racheldiensthütte IN': 'float64',\n",
    "    'Racheldiensthütte OUT': 'float64',\n",
    "    'Sagwassersäge IN': 'float64',\n",
    "    'Sagwassersäge OUT': 'float64',\n",
    "    'Scheuereck IN': 'float64',\n",
    "    'Scheuereck OUT': 'float64',\n",
    "    'Schillerstraße IN': 'float64',\n",
    "    'Schillerstraße OUT': 'float64',\n",
    "    'Schwarzbachbrücke IN': 'float64',\n",
    "    'Schwarzbachbrücke OUT': 'float64',\n",
    "    'Falkenstein 2 OUT': 'float64',\n",
    "    'Falkenstein 2 IN': 'float64',\n",
    "    'Lusen 2 IN': 'float64',\n",
    "    'Lusen 2 OUT': 'float64',\n",
    "    'Lusen 3 IN': 'float64',\n",
    "    'Lusen 3 OUT': 'float64',\n",
    "    'Waldhausreibe IN': 'float64',\n",
    "    'Waldhausreibe OUT': 'float64',\n",
    "    'Waldspielgelände IN': 'float64',\n",
    "    'Waldspielgelände OUT': 'float64',\n",
    "    'Wistlberg IN': 'float64',\n",
    "    'Wistlberg OUT': 'float64',\n",
    "    'Bucina IN': 'float64',\n",
    "    'Bucina OUT': 'float64',\n",
    "    'Falkenstein 1 IN': 'float64',\n",
    "    'Falkenstein 1 OUT': 'float64',\n",
    "    'Lusen 1 IN': 'float64',\n",
    "    'Lusen 1 OUT': 'float64',\n",
    "    'Trinkwassertalsperre IN': 'float64',\n",
    "    'Trinkwassertalsperre OUT': 'float64',\n",
    "    'ZScore_Daily_Max_Temperature (°C)': 'float64',\n",
    "    'ZScore_Daily_Max_Relative Humidity (%)': 'float64',\n",
    "    'ZScore_Daily_Max_Wind Speed (km/h)': 'float64',\n",
    "    'Distance_to_Nearest_Holiday_Bayern': 'float64',\n",
    "    'Distance_to_Nearest_Holiday_CZ': 'float64'\n",
    "}\n",
    "\n",
    "# Apply data types\n",
    "df = df.astype(dtype_dict)\n",
    "\n",
    "# Set 'Time' column as index\n",
    "df.set_index('Time', inplace=True)\n",
    "\n",
    "# Add 'Hour' column based on the index\n",
    "df[\"Hour\"] = df.index.hour\n",
    "\n",
    "# Convert 'Hour' to categorical\n",
    "df['Hour'] = pd.Categorical(df['Hour'])\n",
    "\n",
    "# Reset the index to make 'Time' a column again\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14328 entries, 2023-01-01 00:00:00 to 2024-08-19 23:00:00\n",
      "Data columns (total 93 columns):\n",
      " #   Column                                         Non-Null Count  Dtype   \n",
      "---  ------                                         --------------  -----   \n",
      " 0   Bayerisch Eisenstein IN                        14050 non-null  float64 \n",
      " 1   Bayerisch Eisenstein OUT                       14050 non-null  float64 \n",
      " 2   Brechhäuslau IN                                14049 non-null  float64 \n",
      " 3   Brechhäuslau OUT                               14049 non-null  float64 \n",
      " 4   Deffernik IN                                   13773 non-null  float64 \n",
      " 5   Deffernik OUT                                  13773 non-null  float64 \n",
      " 6   Diensthüttenstraße IN                          13906 non-null  float64 \n",
      " 7   Diensthüttenstraße OUT                         13906 non-null  float64 \n",
      " 8   Felswandergebiet IN                            13643 non-null  float64 \n",
      " 9   Felswandergebiet OUT                           13643 non-null  float64 \n",
      " 10  Ferdinandsthal IN                              14049 non-null  float64 \n",
      " 11  Ferdinandsthal OUT                             14049 non-null  float64 \n",
      " 12  Fredenbrücke IN                                13643 non-null  float64 \n",
      " 13  Fredenbrücke OUT                               13643 non-null  float64 \n",
      " 14  Gfäll IN                                       14028 non-null  float64 \n",
      " 15  Gfäll OUT                                      14028 non-null  float64 \n",
      " 16  Gsenget IN                                     14008 non-null  float64 \n",
      " 17  Gsenget OUT                                    14008 non-null  float64 \n",
      " 18  Klingenbrunner Wald IN                         12516 non-null  float64 \n",
      " 19  Klingenbrunner Wald OUT                        12516 non-null  float64 \n",
      " 20  Klosterfilz IN                                 14030 non-null  float64 \n",
      " 21  Klosterfilz OUT                                14030 non-null  float64 \n",
      " 22  Racheldiensthütte IN                           14030 non-null  float64 \n",
      " 23  Racheldiensthütte OUT                          14030 non-null  float64 \n",
      " 24  Sagwassersäge IN                               13643 non-null  float64 \n",
      " 25  Sagwassersäge OUT                              13643 non-null  float64 \n",
      " 26  Scheuereck IN                                  13474 non-null  float64 \n",
      " 27  Scheuereck OUT                                 13474 non-null  float64 \n",
      " 28  Schillerstraße IN                              14051 non-null  float64 \n",
      " 29  Schillerstraße OUT                             14051 non-null  float64 \n",
      " 30  Schwarzbachbrücke IN                           13643 non-null  float64 \n",
      " 31  Schwarzbachbrücke OUT                          13643 non-null  float64 \n",
      " 32  Falkenstein 2 OUT                              14328 non-null  float64 \n",
      " 33  Falkenstein 2 IN                               14328 non-null  float64 \n",
      " 34  Lusen 2 IN                                     14328 non-null  float64 \n",
      " 35  Lusen 2 OUT                                    14328 non-null  float64 \n",
      " 36  Lusen 3 IN                                     14328 non-null  float64 \n",
      " 37  Lusen 3 OUT                                    14328 non-null  float64 \n",
      " 38  Waldhausreibe IN                               13842 non-null  float64 \n",
      " 39  Waldhausreibe OUT                              13842 non-null  float64 \n",
      " 40  Waldspielgelände IN                            14029 non-null  float64 \n",
      " 41  Waldspielgelände OUT                           14029 non-null  float64 \n",
      " 42  Wistlberg IN                                   13621 non-null  float64 \n",
      " 43  Wistlberg OUT                                  13621 non-null  float64 \n",
      " 44  Bucina IN                                      13642 non-null  float64 \n",
      " 45  Bucina OUT                                     13644 non-null  float64 \n",
      " 46  Falkenstein 1 IN                               14328 non-null  float64 \n",
      " 47  Falkenstein 1 OUT                              14328 non-null  float64 \n",
      " 48  Lusen 1 IN                                     14325 non-null  float64 \n",
      " 49  Lusen 1 OUT                                    14325 non-null  float64 \n",
      " 50  Trinkwassertalsperre IN                        14010 non-null  float64 \n",
      " 51  Trinkwassertalsperre OUT                       14010 non-null  float64 \n",
      " 52  traffic_abs                                    14328 non-null  float64 \n",
      " 53  sum_IN_abs                                     14328 non-null  float64 \n",
      " 54  sum_OUT_abs                                    14328 non-null  float64 \n",
      " 55  Temperature (°C)                               13633 non-null  float64 \n",
      " 56  Relative Humidity (%)                          13633 non-null  float64 \n",
      " 57  Wind Speed (km/h)                              13633 non-null  float64 \n",
      " 58  Tag                                            14328 non-null  float64 \n",
      " 59  Monat                                          14328 non-null  float64 \n",
      " 60  Wochentag                                      14328 non-null  category\n",
      " 61  Wochenende                                     14328 non-null  category\n",
      " 62  Jahreszeit                                     14328 non-null  category\n",
      " 63  Laubfärbung                                    14328 non-null  category\n",
      " 64  Schulferien_Bayern                             14328 non-null  category\n",
      " 65  Schulferien_CZ                                 14328 non-null  category\n",
      " 66  Feiertag_Bayern                                14328 non-null  category\n",
      " 67  Feiertag_CZ                                    14328 non-null  category\n",
      " 68  HEH_geoeffnet                                  14328 non-null  category\n",
      " 69  HZW_geoeffnet                                  14328 non-null  category\n",
      " 70  WGM_geoeffnet                                  14328 non-null  category\n",
      " 71  Lusenschutzhaus_geoeffnet                      14328 non-null  category\n",
      " 72  Racheldiensthuette_geoeffnet                   14328 non-null  category\n",
      " 73  Falkensteinschutzhaus_geoeffnet                14328 non-null  category\n",
      " 74  Schwellhaeusl_geoeffnet                        14328 non-null  category\n",
      " 75  Nationalparkzentrum Falkenstein IN             14328 non-null  float64 \n",
      " 76  Nationalparkzentrum Falkenstein OUT            14328 non-null  float64 \n",
      " 77  Nationalparkzentrum Lusen IN                   14328 non-null  float64 \n",
      " 78  Nationalparkzentrum Lusen OUT                  14328 non-null  float64 \n",
      " 79  Falkenstein-Schwellhäusl IN                    14051 non-null  float64 \n",
      " 80  Falkenstein-Schwellhäusl OUT                   14051 non-null  float64 \n",
      " 81  Rachel-Spiegelau IN                            14030 non-null  float64 \n",
      " 82  Rachel-Spiegelau OUT                           14030 non-null  float64 \n",
      " 83  Scheuereck-Schachten-Trinkwassertalsperre IN   14010 non-null  float64 \n",
      " 84  Scheuereck-Schachten-Trinkwassertalsperre OUT  14010 non-null  float64 \n",
      " 85  Lusen-Mauth-Finsterau IN                       13842 non-null  float64 \n",
      " 86  Lusen-Mauth-Finsterau OUT                      13842 non-null  float64 \n",
      " 87  ZScore_Daily_Max_Temperature (°C)              14328 non-null  float64 \n",
      " 88  ZScore_Daily_Max_Relative Humidity (%)         14328 non-null  float64 \n",
      " 89  ZScore_Daily_Max_Wind Speed (km/h)             14328 non-null  float64 \n",
      " 90  Distance_to_Nearest_Holiday_Bayern             14328 non-null  float64 \n",
      " 91  Distance_to_Nearest_Holiday_CZ                 14328 non-null  float64 \n",
      " 92  Hour                                           14328 non-null  category\n",
      "dtypes: category(16), float64(77)\n",
      "memory usage: 8.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'Time' is in datetime format\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Set 'Time' as the index\n",
    "df.set_index('Time', inplace=True)\n",
    "\n",
    "# Slice the data from January 1, 2023, to August 19, 2024\n",
    "df = df.loc['2023-01-01':'2024-08-19']\n",
    "# Display the info to check data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>Felswandergebiet OUT</th>\n",
       "      <th>...</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre IN</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre OUT</th>\n",
       "      <th>Lusen-Mauth-Finsterau IN</th>\n",
       "      <th>Lusen-Mauth-Finsterau OUT</th>\n",
       "      <th>ZScore_Daily_Max_Temperature (°C)</th>\n",
       "      <th>ZScore_Daily_Max_Relative Humidity (%)</th>\n",
       "      <th>ZScore_Daily_Max_Wind Speed (km/h)</th>\n",
       "      <th>Distance_to_Nearest_Holiday_Bayern</th>\n",
       "      <th>Distance_to_Nearest_Holiday_CZ</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-19 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 20:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "Time                                                                     \n",
       "2024-08-19 19:00:00                      NaN                       NaN   \n",
       "2024-08-19 20:00:00                      NaN                       NaN   \n",
       "2024-08-19 21:00:00                      NaN                       NaN   \n",
       "2024-08-19 22:00:00                      NaN                       NaN   \n",
       "2024-08-19 23:00:00                      NaN                       NaN   \n",
       "\n",
       "                     Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  \\\n",
       "Time                                                                   \n",
       "2024-08-19 19:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 20:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 21:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 22:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 23:00:00              NaN               NaN           NaN   \n",
       "\n",
       "                     Deffernik OUT  Diensthüttenstraße IN  \\\n",
       "Time                                                        \n",
       "2024-08-19 19:00:00            NaN                    NaN   \n",
       "2024-08-19 20:00:00            NaN                    NaN   \n",
       "2024-08-19 21:00:00            NaN                    NaN   \n",
       "2024-08-19 22:00:00            NaN                    NaN   \n",
       "2024-08-19 23:00:00            NaN                    NaN   \n",
       "\n",
       "                     Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "Time                                                               \n",
       "2024-08-19 19:00:00                     NaN                  NaN   \n",
       "2024-08-19 20:00:00                     NaN                  NaN   \n",
       "2024-08-19 21:00:00                     NaN                  NaN   \n",
       "2024-08-19 22:00:00                     NaN                  NaN   \n",
       "2024-08-19 23:00:00                     NaN                  NaN   \n",
       "\n",
       "                     Felswandergebiet OUT  ...  \\\n",
       "Time                                       ...   \n",
       "2024-08-19 19:00:00                   NaN  ...   \n",
       "2024-08-19 20:00:00                   NaN  ...   \n",
       "2024-08-19 21:00:00                   NaN  ...   \n",
       "2024-08-19 22:00:00                   NaN  ...   \n",
       "2024-08-19 23:00:00                   NaN  ...   \n",
       "\n",
       "                     Scheuereck-Schachten-Trinkwassertalsperre IN  \\\n",
       "Time                                                                \n",
       "2024-08-19 19:00:00                                           NaN   \n",
       "2024-08-19 20:00:00                                           NaN   \n",
       "2024-08-19 21:00:00                                           NaN   \n",
       "2024-08-19 22:00:00                                           NaN   \n",
       "2024-08-19 23:00:00                                           NaN   \n",
       "\n",
       "                     Scheuereck-Schachten-Trinkwassertalsperre OUT  \\\n",
       "Time                                                                 \n",
       "2024-08-19 19:00:00                                            NaN   \n",
       "2024-08-19 20:00:00                                            NaN   \n",
       "2024-08-19 21:00:00                                            NaN   \n",
       "2024-08-19 22:00:00                                            NaN   \n",
       "2024-08-19 23:00:00                                            NaN   \n",
       "\n",
       "                     Lusen-Mauth-Finsterau IN  Lusen-Mauth-Finsterau OUT  \\\n",
       "Time                                                                       \n",
       "2024-08-19 19:00:00                       2.0                        2.0   \n",
       "2024-08-19 20:00:00                       0.0                        3.0   \n",
       "2024-08-19 21:00:00                       0.0                        0.0   \n",
       "2024-08-19 22:00:00                       0.0                        0.0   \n",
       "2024-08-19 23:00:00                       0.0                        0.0   \n",
       "\n",
       "                     ZScore_Daily_Max_Temperature (°C)  \\\n",
       "Time                                                     \n",
       "2024-08-19 19:00:00                          -0.489326   \n",
       "2024-08-19 20:00:00                          -0.489326   \n",
       "2024-08-19 21:00:00                          -0.489326   \n",
       "2024-08-19 22:00:00                          -0.489326   \n",
       "2024-08-19 23:00:00                          -0.489326   \n",
       "\n",
       "                     ZScore_Daily_Max_Relative Humidity (%)  \\\n",
       "Time                                                          \n",
       "2024-08-19 19:00:00                                0.535474   \n",
       "2024-08-19 20:00:00                                0.535474   \n",
       "2024-08-19 21:00:00                                0.535474   \n",
       "2024-08-19 22:00:00                                0.535474   \n",
       "2024-08-19 23:00:00                                0.535474   \n",
       "\n",
       "                     ZScore_Daily_Max_Wind Speed (km/h)  \\\n",
       "Time                                                      \n",
       "2024-08-19 19:00:00                            0.794311   \n",
       "2024-08-19 20:00:00                            0.794311   \n",
       "2024-08-19 21:00:00                            0.794311   \n",
       "2024-08-19 22:00:00                            0.794311   \n",
       "2024-08-19 23:00:00                            0.794311   \n",
       "\n",
       "                     Distance_to_Nearest_Holiday_Bayern  \\\n",
       "Time                                                      \n",
       "2024-08-19 19:00:00                                 4.0   \n",
       "2024-08-19 20:00:00                                 4.0   \n",
       "2024-08-19 21:00:00                                 4.0   \n",
       "2024-08-19 22:00:00                                 4.0   \n",
       "2024-08-19 23:00:00                                 4.0   \n",
       "\n",
       "                     Distance_to_Nearest_Holiday_CZ  Hour  \n",
       "Time                                                       \n",
       "2024-08-19 19:00:00                            40.0    19  \n",
       "2024-08-19 20:00:00                            40.0    20  \n",
       "2024-08-19 21:00:00                            40.0    21  \n",
       "2024-08-19 22:00:00                            40.0    22  \n",
       "2024-08-19 23:00:00                            40.0    23  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Falkenstein-Schwellhäusl IN' has its first missing value on 2024-08-08 11:00:00\n",
      "Column 'Rachel-Spiegelau IN' has its first missing value on 2024-08-07 14:00:00\n",
      "Column 'Nationalparkzentrum Falkenstein IN' has no missing values\n",
      "Column 'Nationalparkzentrum Lusen IN' has no missing values\n",
      "Column 'Lusen-Mauth-Finsterau IN' has its first missing value on 2024-07-23 00:00:00\n",
      "Column 'Scheuereck-Schachten-Trinkwassertalsperre IN' has its first missing value on 2024-08-06 18:00:00\n",
      "Column 'Falkenstein-Schwellhäusl OUT' has its first missing value on 2024-08-08 11:00:00\n",
      "Column 'Rachel-Spiegelau OUT' has its first missing value on 2024-08-07 14:00:00\n",
      "Column 'Nationalparkzentrum Falkenstein OUT' has no missing values\n",
      "Column 'Nationalparkzentrum Lusen OUT' has no missing values\n",
      "Column 'Lusen-Mauth-Finsterau OUT' has its first missing value on 2024-07-23 00:00:00\n",
      "Column 'Scheuereck-Schachten-Trinkwassertalsperre OUT' has its first missing value on 2024-08-06 18:00:00\n"
     ]
    }
   ],
   "source": [
    "region_columns = [\n",
    "    'Falkenstein-Schwellhäusl IN', \n",
    "    'Rachel-Spiegelau IN', \n",
    "    'Nationalparkzentrum Falkenstein IN',\n",
    "    'Nationalparkzentrum Lusen IN', \n",
    "    'Lusen-Mauth-Finsterau IN', \n",
    "    'Scheuereck-Schachten-Trinkwassertalsperre IN',\n",
    "    'Falkenstein-Schwellhäusl OUT', \n",
    "    'Rachel-Spiegelau OUT', \n",
    "    'Nationalparkzentrum Falkenstein OUT',\n",
    "    'Nationalparkzentrum Lusen OUT', \n",
    "    'Lusen-Mauth-Finsterau OUT', \n",
    "    'Scheuereck-Schachten-Trinkwassertalsperre OUT'\n",
    "]\n",
    "\n",
    "for column in region_columns:\n",
    "    if column in df.columns:\n",
    "        missing_dates = df[df[column].isna()].index\n",
    "        if not missing_dates.empty:\n",
    "            first_missing_date = missing_dates[0]\n",
    "            print(f\"Column '{column}' has its first missing value on {first_missing_date}\")\n",
    "        else:\n",
    "            print(f\"Column '{column}' has no missing values\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' is not in the DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\garov\\.pyenv-win-venv\\envs\\bavforest\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-07-22\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\garov\\.pyenv-win-venv\\envs\\bavforest\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\garov\\.pyenv-win-venv\\envs\\bavforest\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time'"
     ]
    }
   ],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the data from January 1, 2023, to July 22, 2024\n",
    "df = df.loc['2023-01-01':'2024-07-22']\n",
    "# Display the info to check data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "LATITUDE = 49.31452390542327\n",
    "LONGITUDE = 12.711573421032\n",
    "\n",
    "# Define start and end dates for inference\n",
    "#start_date = datetime.now()\n",
    "#end_date = start_date + pd.Timedelta(days=7)\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime.now() + timedelta(days=7)\n",
    "\n",
    "def get_hourly_data_forecasted(bavarian_forest):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fetch hourly weather data for the Bavarian Forest - forecasted from todays date\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Hourly weather data\n",
    "    \n",
    "    \"\"\"\n",
    "    data = Hourly(bavarian_forest, start_date, end_date)\n",
    "    data = data.fetch()\n",
    "\n",
    "    # Reset the index\n",
    "    data.reset_index(inplace=True)\n",
    "    return data \n",
    "\n",
    "\n",
    "def source_weather_data():\n",
    "\n",
    "    \"\"\"\n",
    "    Source the weather data from METEOSTAT API\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Hourly weather data for the Bavarian Forest National Park for the next 7 days\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create a Point object for the Bavarian Forest National Park entry\n",
    "    bavarian_forest = Point(lat=LATITUDE, lon=LONGITUDE)\n",
    "    bavarian_forest.max_count = 10\n",
    "\n",
    "    print(bavarian_forest.max_count)\n",
    "\n",
    "    # Fetch hourly data for the location\n",
    "    weather_hourly = get_hourly_data_forecasted(bavarian_forest)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    weather_hourly = weather_hourly.drop(columns=['dwpt', 'wdir', 'wpgt', 'pres', 'tsun', 'prcp', 'snow'])\n",
    "\n",
    "    # Convert the 'Time' column to datetime format\n",
    "    weather_hourly['time'] = pd.to_datetime(weather_hourly['time'])\n",
    "    return weather_hourly\n",
    "\n",
    "# Source the weather data\n",
    "weather_data_df = source_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wspd</th>\n",
       "      <th>coco_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15247</th>\n",
       "      <td>2024-09-27 07:00:00</td>\n",
       "      <td>10.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15248</th>\n",
       "      <td>2024-09-27 08:00:00</td>\n",
       "      <td>11.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15249</th>\n",
       "      <td>2024-09-27 09:00:00</td>\n",
       "      <td>12.7</td>\n",
       "      <td>83.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15250</th>\n",
       "      <td>2024-09-27 10:00:00</td>\n",
       "      <td>13.7</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15251</th>\n",
       "      <td>2024-09-27 11:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  temp  rhum  wspd  coco_2\n",
       "15247 2024-09-27 07:00:00  10.6  91.0  14.8       3\n",
       "15248 2024-09-27 08:00:00  11.7  88.0  16.7       3\n",
       "15249 2024-09-27 09:00:00  12.7  83.0  16.7       3\n",
       "15250 2024-09-27 10:00:00  13.7  75.0  18.5       3\n",
       "15251 2024-09-27 11:00:00  14.3  73.0  20.4       3"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_to_coco_2_mapping = {\n",
    "    1: 1,  # Clear\n",
    "    2: 1,  # Fair\n",
    "    3: 2,  # Cloudy\n",
    "    4: 2,  # Overcast\n",
    "    5: 2,  # Fog\n",
    "    6: 5,  # Freezing Fog\n",
    "    7: 3,  # Light Rain\n",
    "    8: 3,  # Rain\n",
    "    9: 3,  # Heavy Rain\n",
    "    10: 5, # Freezing Rain\n",
    "    11: 5, # Heavy Freezing Rain\n",
    "    12: 5, # Sleet\n",
    "    13: 5, # Heavy Sleet\n",
    "    14: 4, # Light Snowfall\n",
    "    15: 4, # Snowfall\n",
    "    16: 4, # Heavy Snowfall\n",
    "    17: 3, # Rain Shower\n",
    "    18: 3, # Heavy Rain Shower\n",
    "    19: 3, # Sleet Shower\n",
    "    20: 5, # Heavy Sleet Shower\n",
    "    21: 4, # Snow Shower\n",
    "    22: 4, # Heavy Snow Shower\n",
    "    23: 6, # Lightning\n",
    "    24: 6, # Hail\n",
    "    25: 6, # Thunderstorm\\\n",
    "    26: 6, # Heavy Thunderstorm\n",
    "    27: 6  # Storm\n",
    "}\n",
    "\n",
    "# Creating the new 'coco_2' column based on the mapping\n",
    "weather_data_df['coco_2'] = weather_data_df['coco'].map(coco_to_coco_2_mapping)\n",
    "\n",
    "# Drop the original 'coco' column\n",
    "weather_data_df = weather_data_df.drop(columns=['coco'])\n",
    "\n",
    "weather_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "15247    False\n",
       "15248    False\n",
       "15249    False\n",
       "15250    False\n",
       "15251    False\n",
       "Name: coco_2, Length: 15252, dtype: bool"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data_df[\"coco_2\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert the 'time' column to datetime type\n",
    "weather_data_df['time'] = pd.to_datetime(weather_data_df['time'])\n",
    "\n",
    "# Step 2: Set the 'time' column as the index\n",
    "weather_data_df = weather_data_df.set_index('time')\n",
    "\n",
    "# Optionally, sort the index if needed\n",
    "weather_data_df = weather_data_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayerisch Eisenstein IN</th>\n",
       "      <th>Bayerisch Eisenstein OUT</th>\n",
       "      <th>Brechhäuslau IN</th>\n",
       "      <th>Brechhäuslau OUT</th>\n",
       "      <th>Deffernik IN</th>\n",
       "      <th>Deffernik OUT</th>\n",
       "      <th>Diensthüttenstraße IN</th>\n",
       "      <th>Diensthüttenstraße OUT</th>\n",
       "      <th>Felswandergebiet IN</th>\n",
       "      <th>Felswandergebiet OUT</th>\n",
       "      <th>...</th>\n",
       "      <th>Scheuereck-Schachten-Trinkwassertalsperre OUT</th>\n",
       "      <th>Lusen-Mauth-Finsterau IN</th>\n",
       "      <th>Lusen-Mauth-Finsterau OUT</th>\n",
       "      <th>ZScore_Daily_Max_Temperature (°C)</th>\n",
       "      <th>ZScore_Daily_Max_Relative Humidity (%)</th>\n",
       "      <th>ZScore_Daily_Max_Wind Speed (km/h)</th>\n",
       "      <th>Distance_to_Nearest_Holiday_Bayern</th>\n",
       "      <th>Distance_to_Nearest_Holiday_CZ</th>\n",
       "      <th>Hour</th>\n",
       "      <th>coco_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-19 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 20:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.535474</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bayerisch Eisenstein IN  Bayerisch Eisenstein OUT  \\\n",
       "Time                                                                     \n",
       "2024-08-19 19:00:00                      NaN                       NaN   \n",
       "2024-08-19 20:00:00                      NaN                       NaN   \n",
       "2024-08-19 21:00:00                      NaN                       NaN   \n",
       "2024-08-19 22:00:00                      NaN                       NaN   \n",
       "2024-08-19 23:00:00                      NaN                       NaN   \n",
       "\n",
       "                     Brechhäuslau IN  Brechhäuslau OUT  Deffernik IN  \\\n",
       "Time                                                                   \n",
       "2024-08-19 19:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 20:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 21:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 22:00:00              NaN               NaN           NaN   \n",
       "2024-08-19 23:00:00              NaN               NaN           NaN   \n",
       "\n",
       "                     Deffernik OUT  Diensthüttenstraße IN  \\\n",
       "Time                                                        \n",
       "2024-08-19 19:00:00            NaN                    NaN   \n",
       "2024-08-19 20:00:00            NaN                    NaN   \n",
       "2024-08-19 21:00:00            NaN                    NaN   \n",
       "2024-08-19 22:00:00            NaN                    NaN   \n",
       "2024-08-19 23:00:00            NaN                    NaN   \n",
       "\n",
       "                     Diensthüttenstraße OUT  Felswandergebiet IN  \\\n",
       "Time                                                               \n",
       "2024-08-19 19:00:00                     NaN                  NaN   \n",
       "2024-08-19 20:00:00                     NaN                  NaN   \n",
       "2024-08-19 21:00:00                     NaN                  NaN   \n",
       "2024-08-19 22:00:00                     NaN                  NaN   \n",
       "2024-08-19 23:00:00                     NaN                  NaN   \n",
       "\n",
       "                     Felswandergebiet OUT  ...  \\\n",
       "Time                                       ...   \n",
       "2024-08-19 19:00:00                   NaN  ...   \n",
       "2024-08-19 20:00:00                   NaN  ...   \n",
       "2024-08-19 21:00:00                   NaN  ...   \n",
       "2024-08-19 22:00:00                   NaN  ...   \n",
       "2024-08-19 23:00:00                   NaN  ...   \n",
       "\n",
       "                     Scheuereck-Schachten-Trinkwassertalsperre OUT  \\\n",
       "Time                                                                 \n",
       "2024-08-19 19:00:00                                            NaN   \n",
       "2024-08-19 20:00:00                                            NaN   \n",
       "2024-08-19 21:00:00                                            NaN   \n",
       "2024-08-19 22:00:00                                            NaN   \n",
       "2024-08-19 23:00:00                                            NaN   \n",
       "\n",
       "                     Lusen-Mauth-Finsterau IN  Lusen-Mauth-Finsterau OUT  \\\n",
       "Time                                                                       \n",
       "2024-08-19 19:00:00                       2.0                        2.0   \n",
       "2024-08-19 20:00:00                       0.0                        3.0   \n",
       "2024-08-19 21:00:00                       0.0                        0.0   \n",
       "2024-08-19 22:00:00                       0.0                        0.0   \n",
       "2024-08-19 23:00:00                       0.0                        0.0   \n",
       "\n",
       "                     ZScore_Daily_Max_Temperature (°C)  \\\n",
       "Time                                                     \n",
       "2024-08-19 19:00:00                          -0.489326   \n",
       "2024-08-19 20:00:00                          -0.489326   \n",
       "2024-08-19 21:00:00                          -0.489326   \n",
       "2024-08-19 22:00:00                          -0.489326   \n",
       "2024-08-19 23:00:00                          -0.489326   \n",
       "\n",
       "                     ZScore_Daily_Max_Relative Humidity (%)  \\\n",
       "Time                                                          \n",
       "2024-08-19 19:00:00                                0.535474   \n",
       "2024-08-19 20:00:00                                0.535474   \n",
       "2024-08-19 21:00:00                                0.535474   \n",
       "2024-08-19 22:00:00                                0.535474   \n",
       "2024-08-19 23:00:00                                0.535474   \n",
       "\n",
       "                     ZScore_Daily_Max_Wind Speed (km/h)  \\\n",
       "Time                                                      \n",
       "2024-08-19 19:00:00                            0.794311   \n",
       "2024-08-19 20:00:00                            0.794311   \n",
       "2024-08-19 21:00:00                            0.794311   \n",
       "2024-08-19 22:00:00                            0.794311   \n",
       "2024-08-19 23:00:00                            0.794311   \n",
       "\n",
       "                     Distance_to_Nearest_Holiday_Bayern  \\\n",
       "Time                                                      \n",
       "2024-08-19 19:00:00                                 4.0   \n",
       "2024-08-19 20:00:00                                 4.0   \n",
       "2024-08-19 21:00:00                                 4.0   \n",
       "2024-08-19 22:00:00                                 4.0   \n",
       "2024-08-19 23:00:00                                 4.0   \n",
       "\n",
       "                     Distance_to_Nearest_Holiday_CZ  Hour  coco_2  \n",
       "Time                                                               \n",
       "2024-08-19 19:00:00                            40.0    19       2  \n",
       "2024-08-19 20:00:00                            40.0    20       2  \n",
       "2024-08-19 21:00:00                            40.0    21       2  \n",
       "2024-08-19 22:00:00                            40.0    22       2  \n",
       "2024-08-19 23:00:00                            40.0    23       2  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['coco_2'] = weather_data_df['coco_2'].reindex(df.index)\n",
    "\n",
    "# df['coco'] = weather_data_df['coco'].reindex(df.index)\n",
    "\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to apply cyclic transformation\n",
    "cyclic_features = ['Tag', 'Monat', 'Hour', 'Wochentag']\n",
    "\n",
    "# Convert categorical features to numeric if they are not already\n",
    "for feature in cyclic_features:\n",
    "    if feature in df.columns:\n",
    "        if pd.api.types.is_categorical_dtype(df[feature]):\n",
    "            df[feature] = df[feature].cat.codes  # Convert categorical to numeric codes\n",
    "        \n",
    "        max_value = df[feature].max()  # Get max value for scaling\n",
    "        \n",
    "        # Apply sine and cosine transformations\n",
    "        df[f'{feature}_sin'] = np.sin(2 * np.pi * df[feature] / max_value)\n",
    "        df[f'{feature}_cos'] = np.cos(2 * np.pi * df[feature] / max_value)\n",
    "    else:\n",
    "        print(f\"Warning: Feature '{feature}' not found in DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features to normalize\n",
    "standardized_features = ['Temperature (°C)', 'Relative Humidity (%)', 'Wind Speed (km/h)', 'Distance_to_Nearest_Holiday_Bayern', 'Distance_to_Nearest_Holiday_CZ']\n",
    "\n",
    "# Loop through each numeric feature and apply z-score normalization\n",
    "for feature in standardized_features:\n",
    "    if feature in df.columns:\n",
    "        mean_value = df[feature].mean()  # Calculate mean\n",
    "        std_value = df[feature].std()    # Calculate standard deviation\n",
    "        \n",
    "        # Apply z-score normalization\n",
    "        df[feature] = (df[feature] - mean_value) / std_value\n",
    "    else:\n",
    "        print(f\"Warning: Feature '{feature}' not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Jahreszeit', 'coco_2'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Tag', 'Monat', 'Wochentag', 'Hour']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"].loc['2023-01-01':'2024-07-22'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to update\n",
    "columns_to_update = [\n",
    "    'Jahreszeit_Frühling',\n",
    "    'Jahreszeit_Herbst',\n",
    "    'Jahreszeit_Sommer',\n",
    "    'Jahreszeit_Winter',\n",
    "    'coco_2_1',\n",
    "    'coco_2_2',\n",
    "    'coco_2_3',\n",
    "    'coco_2_4',\n",
    "    'coco_2_5',\n",
    "    'coco_2_6'\n",
    "]\n",
    "\n",
    "# Replace TRUE with 1 and FALSE with 0, then convert to category\n",
    "for column in columns_to_update:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].replace({True: 1, False: 0})\n",
    "        df[column] = df[column].astype('category')\n",
    "\n",
    "# Verify changes\n",
    "print(df[columns_to_update].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['object', 'category']).columns:\n",
    "    # Replace 'True' with 1 and 'False' with 0 if the column contains these values\n",
    "    if df[col].astype(str).str.contains('True').any() or df[col].astype(str).str.contains('False').any():\n",
    "        df[col] = df[col].replace({'True': 1, 'False': 0})\n",
    "    \n",
    "    # Convert column to integer if it was replaced\n",
    "    if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "        df[col] = df[col].astype('int')  # Convert to integer type\n",
    "        df[col] = df[col].astype('category')  # Convert to category dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and feature columns\n",
    "target_vars_et = ['traffic_abs', 'sum_IN_abs', 'sum_OUT_abs', 'Lusen-Mauth-Finsterau IN', 'Lusen-Mauth-Finsterau OUT', \n",
    "               'Nationalparkzentrum Lusen IN', 'Nationalparkzentrum Lusen OUT', 'Rachel-Spiegelau IN', 'Rachel-Spiegelau OUT', \n",
    "               'Falkenstein-Schwellhäusl IN', 'Falkenstein-Schwellhäusl OUT', \n",
    "               'Scheuereck-Schachten-Trinkwassertalsperre IN', 'Scheuereck-Schachten-Trinkwassertalsperre OUT', \n",
    "              'Nationalparkzentrum Falkenstein IN', 'Nationalparkzentrum Falkenstein OUT']\n",
    "\n",
    "numeric_features = ['Tag_sin', 'Tag_cos', 'Monat_sin', 'Monat_cos', 'Hour_sin', 'Hour_cos', 'Wochentag_sin', 'Wochentag_cos',\n",
    "                    'Temperature (°C)', 'Relative Humidity (%)', 'Wind Speed (km/h)', \n",
    "                    'ZScore_Daily_Max_Temperature (°C)', \n",
    "                    'ZScore_Daily_Max_Relative Humidity (%)','ZScore_Daily_Max_Wind Speed (km/h)',\n",
    "                    'Distance_to_Nearest_Holiday_Bayern','Distance_to_Nearest_Holiday_CZ']\n",
    "\n",
    "categorical_features = ['Wochenende', 'Jahreszeit_Frühling', 'Jahreszeit_Herbst', 'Jahreszeit_Sommer', 'Jahreszeit_Winter', 'Laubfärbung',\n",
    "                       'coco_2_1', 'coco_2_2', 'coco_2_3', 'coco_2_4', 'coco_2_5', 'coco_2_6',\n",
    "                        'Schulferien_Bayern', 'Schulferien_CZ', \n",
    "                       'Feiertag_Bayern', 'Feiertag_CZ', 'HEH_geoeffnet', 'HZW_geoeffnet', 'WGM_geoeffnet', \n",
    "                       'Lusenschutzhaus_geoeffnet', 'Racheldiensthuette_geoeffnet', 'Falkensteinschutzhaus_geoeffnet', \n",
    "                        'Schwellhaeusl_geoeffnet']\n",
    "\n",
    "for catfeature in categorical_features: \n",
    "    df[catfeature] = df[catfeature].astype(str)\n",
    "\n",
    "# Dictionary to store dataframes\n",
    "target_dataframes_et = {}\n",
    "\n",
    "# Iterate over each target variable\n",
    "for target in target_vars_et:\n",
    "    if target in df.columns:\n",
    "        # Select the target variable and features\n",
    "        target_df_et = df[numeric_features + categorical_features + [target]].copy()\n",
    "        target_dataframes_et[target] = target_df_et\n",
    "        print(f\"DataFrame for target variable '{target}' created.\")\n",
    "    else:\n",
    "        print(f\"Target variable '{target}' is not in the DataFrame columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict_et = {}\n",
    "\n",
    "save_path = r\"C:\\Users\\garov\\OneDrive\\Documents\\GitHub\\bavarian-forest-visitor-monitoring-dssgx-24\"\n",
    "\n",
    "for target in target_vars_et:\n",
    "    # Ensure the target is in the dictionary of processed DataFrames\n",
    "    if target in target_dataframes_et:\n",
    "        df = target_dataframes_et[target]\n",
    "        \n",
    "        # Ensure the DataFrame has a date-time index\n",
    "        if isinstance(df.index, pd.DatetimeIndex):\n",
    "            # Define date ranges for training, testing, and unseen data\n",
    "            train_start = '2023-01-01'\n",
    "            train_end = '2023-12-31'\n",
    "            test_start = '2024-01-01'\n",
    "            test_end = '2024-04-30'\n",
    "            unseen_start = '2024-05-01'\n",
    "            unseen_end = '2024-07-22'\n",
    "            \n",
    "            # Split the data into train, test, and unseen sets based on date ranges\n",
    "            df_train = df.loc[train_start:train_end]\n",
    "            df_test = df.loc[test_start:test_end]\n",
    "            df_unseen = df.loc[unseen_start:unseen_end]\n",
    "            \n",
    "            # Combine train and test data for model training\n",
    "            df_train_and_test = pd.concat([df_train, df_test])\n",
    "            \n",
    "            # Setup PyCaret for the target variable with the combined data\n",
    "            reg_setup = setup(data=df_train_and_test,\n",
    "                              target=target, \n",
    "                              numeric_features=numeric_features, \n",
    "                              categorical_features=categorical_features,\n",
    "                              fold=5,\n",
    "                              preprocess=False,\n",
    "                              data_split_shuffle=False,  # Do not shuffle data to maintain date order\n",
    "                              session_id=123,\n",
    "                              train_size=0.9)  # Use 90% of data for training \n",
    "            \n",
    "            # Train the Extra Trees Regressor model\n",
    "            extra_trees_model = create_model('et')\n",
    "            \n",
    "            # Predict on the unseen data\n",
    "            predictions_unseen = predict_model(extra_trees_model, data=df_unseen)\n",
    "            \n",
    "            # Save the model\n",
    "            save_model(extra_trees_model, f\"{save_path}/extra_trees_{target}\")\n",
    "            \n",
    "            # Save the predictions in the dictionary for future use\n",
    "            predictions_dict_et[f\"extra_trees_{target}\"] = predictions_unseen\n",
    "            \n",
    "            print(f\"Predictions for unseen data saved for {target}\") \n",
    "            \n",
    "            # Optionally, save the predictions to a CSV\n",
    "            # predictions_unseen.to_csv(f\"{save_path}/predictions_unseen_{target}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to load models\n",
    "save_path = r\"C:\\Users\\garov\\OneDrive\\Documents\\GitHub\\bavarian-forest-visitor-monitoring-dssgx-24\"\n",
    "\n",
    "# Define target variable lists\n",
    "target_vars_et = ['traffic_abs', 'sum_IN_abs', 'sum_OUT_abs', 'Lusen-Mauth-Finsterau IN', 'Lusen-Mauth-Finsterau OUT', \n",
    "               'Nationalparkzentrum Lusen IN', 'Nationalparkzentrum Lusen OUT', 'Rachel-Spiegelau IN', 'Rachel-Spiegelau OUT', \n",
    "               'Falkenstein-Schwellhäusl IN', 'Falkenstein-Schwellhäusl OUT', \n",
    "               'Scheuereck-Schachten-Trinkwassertalsperre IN', 'Scheuereck-Schachten-Trinkwassertalsperre OUT', \n",
    "               'Nationalparkzentrum Falkenstein IN', 'Nationalparkzentrum Falkenstein OUT']\n",
    "\n",
    "\n",
    "# Plot feature importance for Extra Trees models\n",
    "for target in target_vars_et:\n",
    "    model_filename = f'extra_trees_{target}'\n",
    "    full_model_path = os.path.join(save_path, model_filename)\n",
    "    \n",
    "    try:\n",
    "        # Load the saved model\n",
    "        loaded_model = load_model(full_model_path)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        print(f\"Feature importance for Extra Trees model on target '{target}':\")\n",
    "        plot_model(loaded_model, plot='feature_all')\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for Extra Trees models\n",
    "for key, predictions_et in predictions_dict_et.items():\n",
    "    target = key.split('_', 2)[-1]  # This assumes the format 'extra_trees_<target>'\n",
    "    \n",
    "    if \"prediction_label\" in predictions_et.columns and target in predictions_et.columns:\n",
    "        predictions_vs_real_et = predictions_et[[target, \"prediction_label\"]].sort_index(ascending=True)\n",
    "        \n",
    "        # Create a line plot using Matplotlib\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(predictions_vs_real_et.index, predictions_vs_real_et[target], label='Actual', color='blue')\n",
    "        plt.plot(predictions_vs_real_et.index, predictions_vs_real_et[\"prediction_label\"], label='Predicted', color='red')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f\"Predictions vs. Real Values for {key}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Columns '{target}' and 'prediction_label' not found in predictions for {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, predictions_et in predictions_dict_et.items():\n",
    "    target = key.split('_', 2)[-1]  # This assumes the format 'extra_trees_<target>'\n",
    "    \n",
    "    if \"prediction_label\" in predictions_et.columns and target in predictions_et.columns:\n",
    "        # Resample predictions and actual values on a daily basis\n",
    "        daily_prediction_comparison = predictions_et[[target, \"prediction_label\"]].resample(\"1d\").sum()\n",
    "\n",
    "        # Calculate the mean absolute error (MAE)\n",
    "        daily_prediction_comparison[\"mae\"] = abs(daily_prediction_comparison[target] - daily_prediction_comparison[\"prediction_label\"])\n",
    "        print(f\"The MAE on a daily basis for {target} is {daily_prediction_comparison['mae'].mean()}.\")\n",
    "\n",
    "        # Plot the actual vs predicted values using Plotly Express\n",
    "        fig = px.line(daily_prediction_comparison, y=[target, \"prediction_label\"],\n",
    "                      labels={\"value\": \"Value\", \"variable\": \"Legend\"},\n",
    "                      title=f\"Daily Predictions vs Actuals for {target}\")\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Columns '{target}' and 'prediction_label' not found in predictions for {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, predictions_et in predictions_dict_et.items():\n",
    "    target = key.split('_', 2)[-1]  # This assumes the format 'extra_trees_<target>'\n",
    "    \n",
    "    if \"prediction_label\" in predictions_et.columns and target in predictions_et.columns:\n",
    "        # Resample predictions and actual values on a daily basis\n",
    "        daily_prediction_comparison = predictions_et[[target, \"prediction_label\"]].resample(\"1d\").sum()\n",
    "\n",
    "        # Calculate the mean absolute error (MAE) on a daily basis\n",
    "        daily_prediction_comparison[\"mae\"] = abs(daily_prediction_comparison[target] - daily_prediction_comparison[\"prediction_label\"])\n",
    "\n",
    "        # Print the average number of people visiting the park (or any other target)\n",
    "        print(f\"On average, {daily_prediction_comparison[target].mean()} people are visiting the park daily for {target}.\")\n",
    "\n",
    "        # Create a box plot of the MAE using Plotly Express\n",
    "        fig_box = px.box(daily_prediction_comparison, y=\"mae\", title=f\"MAE Distribution for {target}\")\n",
    "        fig_box.show()\n",
    "\n",
    "        # Identify the top 50 days with the highest error\n",
    "        high_error_dates = daily_prediction_comparison[\"mae\"].sort_values(ascending=False).head(50)\n",
    "        print(high_error_dates)\n",
    "\n",
    "        # Retrieve and print training data columns using PyCaret's get_config function\n",
    "        X_train = get_config('X_train')\n",
    "        X_train_columns = X_train.columns.to_list()\n",
    "        print(f\"Training columns for {target}: {X_train_columns}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Columns '{target}' and 'prediction_label' not found in predictions for {key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end dates for inference\n",
    "start_date = datetime.now()\n",
    "end_date = datetime.now() + timedelta(days=7)\n",
    "#start_date = datetime(2016, 1, 1)\n",
    "#end_date = datetime (2024, 7, 22)\n",
    "\n",
    "# Coordinates of the Bavarian Forest (Haselbach)\n",
    "# These coordinates are based on the weather recommendation by Google for a Bavarian Forest Weather search\n",
    "LATITUDE = 49.31452390542327\n",
    "LONGITUDE = 12.711573421032\n",
    "\n",
    "# Create an hourly date range for inference\n",
    "inference_index = pd.date_range(\n",
    "    start=pd.to_datetime(start_date),\n",
    "    end=pd.to_datetime(end_date),\n",
    "    freq=\"1h\"\n",
    ")\n",
    "\n",
    "# Create an empty DataFrame for inference with X_train columns\n",
    "inference_df = pd.DataFrame(index=inference_index, columns=X_train_columns)\n",
    "\n",
    "# Ensure the index is at the hourly level by flooring it to the hour\n",
    "inference_df.index = pd.DatetimeIndex(inference_df.index).floor('H')\n",
    "\n",
    "# Drop rows in inference_df that are outside the START_TIME and END_TIME range\n",
    "inference_df = inference_df[(inference_df.index >= pd.Timestamp(start_date).floor('H')) & \n",
    "                            (inference_df.index <= pd.Timestamp(end_date).floor('H'))]\n",
    "\n",
    "inference_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note df2 = visitor center data\n",
    "\n",
    "def load_csv_files_from_aws_s3(path: str, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Loads individual or multiple CSV files from an AWS S3 bucket.\n",
    "    Args:\n",
    "        path (str): The path to the CSV files on AWS S3.\n",
    "        **kwargs: Additional arguments to pass to the read_csv function.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the data from the CSV files.\n",
    "    \"\"\"\n",
    "    df2 = wr.s3.read_csv(path=path, **kwargs)\n",
    "    return df2\n",
    "df2 = load_csv_files_from_aws_s3(\n",
    "    path=\"s3://dssgx-munich-2024-bavarian-forest/preprocessed_data/df_visitcenters_hourly.csv\"\n",
    ")\n",
    "\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def fill_missing_values(data, parameters):\n",
    "    \"\"\"\n",
    "    Fill missing values in the weather data using linear interpolation or zero values.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Processed hourly weather data.\n",
    "        parameters (list): List of column names to process.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with missing values filled.\n",
    "    \"\"\"\n",
    "    total_rows = data.shape[0]\n",
    "\n",
    "    for parameter in parameters:\n",
    "        # Calculate missing values and their percentage\n",
    "        missing_values = data[parameter].isnull().sum()\n",
    "        missing_percentage = (missing_values / total_rows) * 100\n",
    "\n",
    "        # Calculate zero values and their percentage\n",
    "        zero_values = data[parameter].eq(0).sum()\n",
    "        zero_percentage = (zero_values / total_rows) * 100\n",
    "\n",
    "        # Check for missing values in the 'Time' column\n",
    "        if parameter == 'Time' and missing_values > 0:\n",
    "            print(f'Missing values in Time column: {missing_percentage:.2f}%')\n",
    "            print('Please check the missing values in the Time column')\n",
    "            exit()\n",
    "\n",
    "        if missing_values == 0:\n",
    "            print(f'No missing values in {parameter} column')\n",
    "        else:\n",
    "            print(f'Missing values in {parameter} column: {missing_percentage:.2f}%')\n",
    "\n",
    "            if zero_percentage > 60:\n",
    "                # Fill missing values with 0.0 if zero values are significant\n",
    "                print(f'Zero values in {parameter} column: {zero_percentage:.2f}%')\n",
    "                data[parameter].fillna(0.0, inplace=True)\n",
    "                print(f'Missing values in {parameter} column filled with 0.0')\n",
    "            else:\n",
    "                # Use linear interpolation to fill missing values\n",
    "                data[parameter].interpolate(method='linear', inplace=True)\n",
    "                # Round the interpolated values to 2 decimal places\n",
    "                data[parameter] = data[parameter].round(2)\n",
    "                print(f'Missing values in {parameter} column filled using linear interpolation')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_weather_data(weather_data_df):\n",
    "    \"\"\"\n",
    "    Process the hourly weather data by filling missing values.\n",
    "\n",
    "    Args:\n",
    "        weather_data_df (pandas.DataFrame): Hourly weather data.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed weather data with missing values filled.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get the list of columns to process\n",
    "    parameters = weather_data_df.columns.to_list()\n",
    "\n",
    "    print(f'Processing weather data with the following columns: {parameters}')\n",
    "\n",
    "    # Fill missing values in the weather data\n",
    "    imputed_data = fill_missing_values(weather_data_df, parameters)\n",
    "\n",
    "    return imputed_data\n",
    "\n",
    "process_weather_data=weather_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common columns between inference_df and the new DataFrames\n",
    "common_columns_df2 = df2.columns.intersection(inference_df.columns)\n",
    "common_columns_process_weather_data = process_weather_data.columns.intersection(inference_df.columns)\n",
    "\n",
    "# Merge df2 and process_weather_data into inference_df based on datetime index\n",
    "inference_df.update(df2[common_columns_df2])\n",
    "inference_df.update(process_weather_data[common_columns_process_weather_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cyclic_features(df):\n",
    "    \"\"\"\n",
    "    Applies cyclic transformations to various columns based on their specific cyclic patterns\n",
    "    and updates the corresponding columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with a DatetimeIndex and columns for which to apply cyclic transformations.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with cyclic feature columns updated.\n",
    "    \"\"\"\n",
    "    # Ensure the index is a DatetimeIndex\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of the DataFrame must be a DatetimeIndex\")\n",
    "\n",
    "    # Extract features from the datetime index\n",
    "    df['day_of_month'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "\n",
    "    # Define maximum values for cyclic transformations\n",
    "    max_values = {\n",
    "        'day_of_month': 31,  # Maximum number of days in a month\n",
    "        'month': 12,         # Maximum number of months in a year\n",
    "        'hour': 24,          # Maximum number of hours in a day\n",
    "        'day_of_week': 7     # Number of days in a week\n",
    "    }\n",
    "\n",
    "    # Define transformation columns\n",
    "    transformations = {\n",
    "        'day_of_month': ('Tag_sin', 'Tag_cos'),\n",
    "        'month': ('Monat_sin', 'Monat_cos'),\n",
    "        'hour': ('Hour_sin', 'Hour_cos'),\n",
    "        'day_of_week': ('Wochentag_sin', 'Wochentag_cos')\n",
    "    }\n",
    "\n",
    "    # Apply transformations\n",
    "    for feature, (sin_col, cos_col) in transformations.items():\n",
    "        max_value = max_values[feature]\n",
    "        df[sin_col] = np.sin(2 * np.pi * df[feature] / max_value)\n",
    "        df[cos_col] = np.cos(2 * np.pi * df[feature] / max_value)\n",
    "    \n",
    "    # Drop the temporary columns used for transformations\n",
    "    df.drop(columns=['day_of_month', 'month', 'hour', 'day_of_week'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to inference_df\n",
    "inference_df = add_cyclic_features(inference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weather_data(process_weather_data, inference_df):\n",
    "    \"\"\"\n",
    "    Applies z-score normalization to 'temp', 'rhum', and 'wspd' columns in process_weather_data,\n",
    "    then updates the corresponding columns in inference_df with the normalized data, \n",
    "    based on matching the DatetimeIndex.\n",
    "    \n",
    "    Parameters:\n",
    "    process_weather_data (pd.DataFrame): DataFrame with weather data containing 'temp', 'rhum', and 'wspd' columns.\n",
    "    inference_df (pd.DataFrame): DataFrame where normalized data will be placed, matching on DatetimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: inference_df with updated 'Temperature (°C)', 'Relative Humidity (%)', 'Wind Speed (km/h)' columns.\n",
    "    \"\"\"\n",
    "    # Ensure both DataFrames have a DatetimeIndex\n",
    "    if not isinstance(process_weather_data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of process_weather_data must be a DatetimeIndex\")\n",
    "    if not isinstance(inference_df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of inference_df must be a DatetimeIndex\")\n",
    "    \n",
    "    # Ensure the weather columns exist in process_weather_data\n",
    "    required_columns = ['temp', 'rhum', 'wspd']\n",
    "    if not all(col in process_weather_data.columns for col in required_columns):\n",
    "        raise ValueError(f\"process_weather_data must contain columns: {required_columns}\")\n",
    "    \n",
    "    # Z-score normalization function\n",
    "    def z_score_normalize(series):\n",
    "        return (series - series.mean()) / series.std()\n",
    "    \n",
    "    # Apply z-score normalization to 'temp', 'rhum', and 'wspd' columns\n",
    "    process_weather_data['temp_normalized'] = z_score_normalize(process_weather_data['temp'])\n",
    "    process_weather_data['rhum_normalized'] = z_score_normalize(process_weather_data['rhum'])\n",
    "    process_weather_data['wspd_normalized'] = z_score_normalize(process_weather_data['wspd'])\n",
    "    \n",
    "    # Find common DatetimeIndex between the two DataFrames\n",
    "    common_index = process_weather_data.index.intersection(inference_df.index)\n",
    "    \n",
    "    if common_index.empty:\n",
    "        raise ValueError(\"No matching dates found between process_weather_data and inference_df\")\n",
    "    \n",
    "    # Update corresponding columns in inference_df only where DatetimeIndex matches\n",
    "    inference_df = inference_df.copy()  # Make a copy to avoid modifying original\n",
    "    inference_df.loc[common_index, 'Temperature (°C)'] = process_weather_data.loc[common_index, 'temp_normalized']\n",
    "    inference_df.loc[common_index, 'Relative Humidity (%)'] = process_weather_data.loc[common_index, 'rhum_normalized']\n",
    "    inference_df.loc[common_index, 'Wind Speed (km/h)'] = process_weather_data.loc[common_index, 'wspd_normalized']\n",
    "    \n",
    "    return inference_df\n",
    "\n",
    "# Usage\n",
    "inference_df = normalize_weather_data(process_weather_data, inference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_time_column_as_datetime_index(df2):\n",
    "    \"\"\"\n",
    "    Sets the 'Time' column in df2 as the DatetimeIndex and drops the original 'Time' column.\n",
    "    \n",
    "    Parameters:\n",
    "    df2 (pd.DataFrame): DataFrame with a 'Time' column that will be converted to the DatetimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with 'Time' column set as the DatetimeIndex.\n",
    "    \"\"\"\n",
    "    if 'Time' not in df2.columns:\n",
    "        raise ValueError(\"The column 'Time' does not exist in df2\")\n",
    "    \n",
    "    # Convert 'Time' column to datetime\n",
    "    df2['Time'] = pd.to_datetime(df2['Time'])\n",
    "    \n",
    "    # Set 'Time' column as the index\n",
    "    df2 = df2.set_index('Time')\n",
    "    \n",
    "    return df2\n",
    "\n",
    "# Example usage\n",
    "df2 = set_time_column_as_datetime_index(df2)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_columns_and_update(df2, inference_df):\n",
    "    \"\"\"\n",
    "    Updates the columns in inference_df with the corresponding data from df2,\n",
    "    based on matching DatetimeIndex and common column names.\n",
    "    \n",
    "    Parameters:\n",
    "    df2 (pd.DataFrame): DataFrame with data to update inference_df.\n",
    "    inference_df (pd.DataFrame): DataFrame where matched columns will be updated with df2 data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: inference_df with updated data for matching columns based on the DatetimeIndex.\n",
    "    \"\"\"\n",
    "    # Ensure both DataFrames have a DatetimeIndex\n",
    "    if not isinstance(df2.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of df2 must be a DatetimeIndex\")\n",
    "    if not isinstance(inference_df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of inference_df must be a DatetimeIndex\")\n",
    "    \n",
    "    # Find the common DatetimeIndex between the two DataFrames\n",
    "    common_index = df2.index.intersection(inference_df.index)\n",
    "    \n",
    "    if common_index.empty:\n",
    "        raise ValueError(\"No matching dates found between df2 and inference_df\")\n",
    "    \n",
    "    # Find the common columns between the two DataFrames\n",
    "    common_columns = df2.columns.intersection(inference_df.columns)\n",
    "    \n",
    "    if common_columns.empty:\n",
    "        raise ValueError(\"No matching columns found between df2 and inference_df\")\n",
    "    \n",
    "    # Update corresponding columns in inference_df only where both index and columns match\n",
    "    inference_df = inference_df.copy()  # Make a copy to avoid modifying original\n",
    "    inference_df.loc[common_index, common_columns] = df2.loc[common_index, common_columns]\n",
    "    \n",
    "    return inference_df\n",
    "\n",
    "# Example usage\n",
    "inference_df = match_columns_and_update(df2, inference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coco_2_dummies(process_weather_data, inference_df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for the 'coco_2' column in process_weather_data, \n",
    "    and updates the corresponding columns in inference_df where the DatetimeIndex matches.\n",
    "    \n",
    "    Parameters:\n",
    "    process_weather_data (pd.DataFrame): DataFrame containing the 'coco_2' column.\n",
    "    inference_df (pd.DataFrame): DataFrame where dummy columns will be updated, matching on DatetimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: inference_df with updated 'coco_2_1', 'coco_2_2', ..., 'coco_2_6' columns.\n",
    "    \"\"\"\n",
    "    # Ensure both DataFrames have a DatetimeIndex\n",
    "    if not isinstance(process_weather_data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of process_weather_data must be a DatetimeIndex\")\n",
    "    if not isinstance(inference_df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of inference_df must be a DatetimeIndex\")\n",
    "    \n",
    "    # Ensure 'coco_2' exists in process_weather_data\n",
    "    if 'coco_2' not in process_weather_data.columns:\n",
    "        raise ValueError(\"'coco_2' column is missing in process_weather_data\")\n",
    "\n",
    "    # Get dummy codes for 'coco_2'\n",
    "    coco_2_dummies = pd.get_dummies(process_weather_data['coco_2'], prefix='coco_2')\n",
    "\n",
    "    # Find common DatetimeIndex between the two DataFrames\n",
    "    common_index = process_weather_data.index.intersection(inference_df.index)\n",
    "\n",
    "    if common_index.empty:\n",
    "        raise ValueError(\"No matching dates found between process_weather_data and inference_df\")\n",
    "\n",
    "    # Select only the common index from coco_2_dummies\n",
    "    coco_2_dummies_common = coco_2_dummies.loc[common_index]\n",
    "\n",
    "    # Create the columns in inference_df if they don't exist\n",
    "    for i in range(1, 7):  # Assuming there are 6 dummy columns\n",
    "        column_name = f'coco_2_{i}'\n",
    "        if column_name not in inference_df.columns:\n",
    "            inference_df[column_name] = 0  # Initialize with zeros\n",
    "\n",
    "    # Update inference_df with dummy codes where the DatetimeIndex matches\n",
    "    inference_df.loc[common_index, coco_2_dummies_common.columns] = coco_2_dummies_common\n",
    "\n",
    "    return inference_df\n",
    "\n",
    "# Usage\n",
    "inference_df = add_coco_2_dummies(process_weather_data, inference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jahreszeit_dummies(df2, inference_df):\n",
    "    \"\"\"\n",
    "    Creates dummy variables for the 'Jahreszeit' column in df2,\n",
    "    and updates the corresponding columns in inference_df where the DatetimeIndex matches.\n",
    "    \n",
    "    Parameters:\n",
    "    df2 (pd.DataFrame): DataFrame containing the 'Jahreszeit' column.\n",
    "    inference_df (pd.DataFrame): DataFrame where dummy columns will be updated, matching on DatetimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: inference_df with updated 'Jahreszeit_Frühling', 'Jahreszeit_Herbst', \n",
    "                  'Jahreszeit_Sommer', 'Jahreszeit_Winter' columns.\n",
    "    \"\"\"\n",
    "    # Ensure both DataFrames have a DatetimeIndex\n",
    "    if not isinstance(df2.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of df2 must be a DatetimeIndex\")\n",
    "    if not isinstance(inference_df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"The index of inference_df must be a DatetimeIndex\")\n",
    "    \n",
    "    # Ensure 'Jahreszeit' exists in df2\n",
    "    if 'Jahreszeit' not in df2.columns:\n",
    "        raise ValueError(\"'Jahreszeit' column is missing in df2\")\n",
    "\n",
    "    # Get dummy codes for 'Jahreszeit'\n",
    "    jahreszeit_dummies = pd.get_dummies(df2['Jahreszeit'], prefix='Jahreszeit')\n",
    "\n",
    "    # Find common DatetimeIndex between the two DataFrames\n",
    "    common_index = df2.index.intersection(inference_df.index)\n",
    "\n",
    "    if common_index.empty:\n",
    "        raise ValueError(\"No matching dates found between df2 and inference_df\")\n",
    "\n",
    "    # Select only the common index from jahreszeit_dummies\n",
    "    jahreszeit_dummies_common = jahreszeit_dummies.loc[common_index]\n",
    "\n",
    "    # Create the columns in inference_df if they don't exist\n",
    "    for season in ['Frühling', 'Herbst', 'Sommer', 'Winter']:\n",
    "        column_name = f'Jahreszeit_{season}'\n",
    "        if column_name not in inference_df.columns:\n",
    "            inference_df[column_name] = 0  # Initialize with zeros\n",
    "\n",
    "    # Update inference_df with dummy codes where the DatetimeIndex matches\n",
    "    inference_df.loc[common_index, jahreszeit_dummies_common.columns] = jahreszeit_dummies_common\n",
    "\n",
    "    return inference_df\n",
    "\n",
    "# Usage\n",
    "inference_df = add_jahreszeit_dummies(df2, inference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_boolean_to_category(inference_df):\n",
    "    \"\"\"\n",
    "    Converts instances of values equal to TRUE to 1 and FALSE to 0 in all object type columns of inference_df,\n",
    "    then converts these columns to category type.\n",
    "    \n",
    "    Parameters:\n",
    "    inference_df (pd.DataFrame): DataFrame containing object type columns.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated inference_df with converted columns as category type.\n",
    "    \"\"\"\n",
    "    # Identify object type columns\n",
    "    object_columns = inference_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in object_columns:\n",
    "        # Convert TRUE/FALSE strings to 1/0\n",
    "        inference_df[col] = inference_df[col].replace({'TRUE': 1, 'FALSE': 0})\n",
    "\n",
    "        # Convert column to category type\n",
    "        inference_df[col] = inference_df[col].astype('category')\n",
    "\n",
    "    return inference_df\n",
    "\n",
    "# Usage\n",
    "inference_df = convert_boolean_to_category(inference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecasts_for_targets(inference_df, target_vars, model_path):\n",
    "    \"\"\"\n",
    "    Generate forecasts for each target variable using corresponding models.\n",
    "\n",
    "    Parameters:\n",
    "    - inference_df: DataFrame containing features for predictions.\n",
    "    - target_vars: List of target variables.\n",
    "    - model_path: Path to save and load models.\n",
    "\n",
    "    Returns:\n",
    "    - forecasts_dict: Dictionary containing DataFrames with predictions for each target variable.\n",
    "    \"\"\"\n",
    "    forecasts_dict = {}\n",
    "\n",
    "    for target in target_vars:\n",
    "        if target in inference_df.columns:\n",
    "            # Create a copy of inference_df for the current target variable\n",
    "            current_df = inference_df.copy()\n",
    "\n",
    "            # Load the corresponding model for the target variable\n",
    "            model = load_model(f\"{model_path}/extra_trees_{target}\")\n",
    "\n",
    "            # Generate predictions using the model\n",
    "            predictions = predict_model(model, data=current_df)\n",
    "\n",
    "            # Store the predictions in the DataFrame\n",
    "            current_df['predicted_' + target] = predictions['prediction_label']\n",
    "\n",
    "            # Store the DataFrame in the dictionary\n",
    "            forecasts_dict[target] = current_df\n",
    "\n",
    "            print(f\"Forecasts for target variable '{target}' added to DataFrame.\")\n",
    "        else:\n",
    "            print(f\"Target variable '{target}' is not in the inference DataFrame.\")\n",
    "    \n",
    "    return forecasts_dict\n",
    "\n",
    "forecasts = generate_forecasts_for_targets(inference_df, target_vars_et, save_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bavforest",
   "language": "python",
   "name": "bavforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
